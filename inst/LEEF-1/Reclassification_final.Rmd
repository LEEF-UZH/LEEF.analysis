---
title: "Reclassification"
author: "Rainer M Krug"
date: "06/05/2022"
output:
  html_document:
    dev: png
    fig_width: 10
    fig_height: 12
    toc: true
    toc_float: true
    toc_collapsed: true
    code_folding: hide
params:
  output_dir: "~/RRD.Reclassification_final/"
  version_tag: "v1.7.1"
  base: "https://github.com/LEEF-UZH/LEEF.parameter/raw/"
  db: "~/RRD.Reclassification_final/LEEF.RRD.sqlite"
  archive_dir: "/Volumes/LEEF-1_archive/"
  cores: 14
---

# Preparation
1. Set Base to use
This reclassification is based on the classifiers as in the repo at the base URL which speicifies the repo and the reference / tag which should be used for this reclassification
2. Set output path
3. Set database
4. Set Archive Directory
Make sure, that the S3 LEEF archive is mounted and you know the path to the archive as it is needed.


```{r setup_reclass, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  eval = TRUE,
  message = TRUE,
  warning = TRUE
)
library("LEEF.analysis")
library(dplyr)

## 1.
base <- paste0(params$base, params$version_tag, "/")

## 2.
output <-  params$output_dir
dir.create(output, recursive = TRUE, showWarnings = FALSE)

## 3.
db <- params$db
org_db <- db
reclass_db <- gsub(".sqlite", paste0(".", params$version_tag, ".reclass,sqlite"), org_db)
bemovi_reclass_db <- gsub(".sqlite", paste0(".bemovi.sqlite"), reclass_db)
flowcam_reclass_db <- gsub(".sqlite", paste0(".flowcam.sqlite"), bemovi_reclass_db)
filter_db <- gsub(".sqlite", paste0(".filter.sqlite"), flowcam_reclass_db)
bemovi_filter_db <- gsub(".sqlite", paste0(".bemovi.sqlite"), filter_db)
flowcam_filter_db <- gsub(".sqlite", paste0(".flowcam.sqlite"), bemovi_filter_db)


## 4.
archive_dir <- params$archive_dir
if (!file.exists(archive_dir)){
  stop(
    "This is not a problem when not reclassifying! \n",
    "Archive directory '", archive_dir, "' does not exist!\n",
    "Probably not mounted?" 
  )
}
if (!file.exists(file.path(archive_dir, "LEEF.archived.data", "LEEF", "3.archived.data", "extracted"))){
  stop(
    "This is not a problem when not reclassifying! \n",
    "Archive directory is not valid! \n",
    "It does not contain the folder '", file.path(archive_dir, "LEEF.archived.data", "LEEF", "3.archived_data", "extracted"), "'.\n",
    "Probably not mounted?" 
  )
}
```

# DONE - Reclassification of all timestamps

## Flowcam

### Prepare Flowcam
```{r prepare_flowcam}
pdir <- tempfile()
dir.create(pdir, showWarnings = FALSE, recursive = TRUE)

class_constant <- file.path(pdir, "class_constant.rds")
download.file(
  paste0(base, "parameter/flowcam/svm_flowcam_classifiers_20221226_MergedData.rds"), 
  destfile = class_constant,
  mode = "wb"
)

class_increasing <- file.path(pdir, "class_increasing.rds")
download.file(
  paste0(base, "parameter/flowcam/svm_flowcam_classifiers_20221226_MergedData.rds"), 
  destfile = class_increasing,
  mode = "wb"
)

timestamps <- list.files(
  path = file.path(archive_dir, "LEEF.archived.data", "LEEF", "3.archived.data", "extracted"), 
  pattern = "^LEEF\\.fast\\.flowcam\\.",
  recursive = FALSE, 
  full.names = FALSE
)
timestamps <- gsub("^LEEF\\.fast\\.flowcam\\.", "", timestamps)
```

### Classify Flowcam
```{r classify_flowcam}
out <- file.path(output, "flowcam")
if (!file.exists(out)) {
  message("Classifying flowcam...")
  system.time(
    classify_flowcam_archive(
      archive_dir = archive_dir, 
      timestamps = timestamps, 
      algae_traits_name = "algae_traits_filtered.rds", 
      classifier_constant_name = class_constant, 
      classifier_increasing_name = class_increasing, 
      species_tracked = yaml::read_yaml(paste0(base, "parameter/flowcam/flowcam.yml"))$species_tracked,
      output = out,
      mc.cores = params$cores
    )
  )
} else {
  message(
    "Directory ", out, "exists\n",
    "skipping Flowcam."
  )
}
```

### Clean Up Flowcam
```{r cleanup_flowcam}
unlink(pdir)
rm(class_constant, class_increasing, out)
```

## Bemovi magnification 16
### Prepare Bemovi 16
```{r prepare_bemovi_16}
pdir <- tempfile()
dir.create(pdir, showWarnings = FALSE, recursive = TRUE)

class_constant <- file.path(pdir, "class_constant.rds")
download.file(
  paste0(base, "parameter/bemovi.mag.16/svm_video_classifiers_16x_20220706_MergedData.rds"), 
  destfile = class_constant,
  mode = "wb"
)

class_increasing <- file.path(pdir, "class_increasing.rds")
download.file(
  paste0(base, "/parameter/bemovi.mag.16/svm_video_classifiers_16x_20220706_MergedData.rds"), 
  destfile = class_increasing,
  mode = "wb"
)

timestamps <- list.files(
  path = file.path(archive_dir, "LEEF.archived.data", "LEEF", "3.archived.data", "extracted"), 
  pattern = "^LEEF\\.bemovi\\.mag\\.16\\.bemovi\\.",
  recursive = FALSE, 
  full.names = FALSE
)
timestamps <- gsub("^LEEF\\.bemovi\\.mag\\.16\\.bemovi\\.", "", timestamps)
```

### Classify `bemovi_extract.mag.16.yml`
```{r classify_bemovi_16}
out <- file.path(output, "bemovi_mag_16")
if (!file.exists(out)) {
  message("Classifying bemovi_extract.mag.16")
  system.time(
    classify_bemovi_archive( 
      timestamps = timestamps, 
      archive_dir = archive_dir, 
      magnification = 16, 
      classifier_constant_name = class_constant, 
      classifier_increasing_name = class_increasing, 
      bemovi_extract_name = "bemovi_extract.mag.16.yml", 
      species_tracked = yaml::read_yaml(paste0(base, "parameter/bemovi.mag.16/bemovi_extract.mag.16.yml"))$species_tracked,
      output = out,
      mc.cores = params$cores
    )
  )
} else {
  message(
    "Directory ", out, " exists\n",
    "Skipping 'bemovi_extract.mag.16.'"
  )
}
```

### Clean Up Bemovi 16
```{r cleanup_bemovi_16}
unlink(pdir)
rm(pdir, class_constant, class_increasing, out)
```

## Bemovi magnification 25
### Prepare Bemovi 25
```{r prepare_bemovi_25}
pdir <- tempfile()
dir.create(pdir, showWarnings = FALSE, recursive = TRUE)

class_constant <- file.path(pdir, "class_constant.rds")
download.file(
  paste0(base, "parameter/bemovi.mag.25/svm_video_classifiers_25x_20220706_MergedData.rds"), 
  destfile = class_constant,
  mode = "wb"
)

class_increasing <- file.path(pdir, "class_increasing.rds")
download.file(
  paste0(base, "parameter/bemovi.mag.25/svm_video_classifiers_25x_20220706_MergedData.rds"), 
  destfile = class_increasing,
  mode = "wb"
)

timestamps <- list.files(
  path = file.path(archive_dir, "LEEF.archived.data", "LEEF", "3.archived.data", "extracted"), 
  pattern = "^LEEF\\.bemovi\\.mag\\.25\\.bemovi\\.",
  recursive = FALSE, 
  full.names = FALSE
)
timestamps <- gsub("^LEEF\\.bemovi\\.mag\\.25\\.bemovi\\.", "", timestamps)
```

### Classify `bemovi_mag.25` 
```{r classify_bemovi_25}
out <- file.path(output, "bemovi_mag_25")
if (!file.exists(out)) {
  system.time(
    classify_bemovi_archive( 
      timestamps = timestamps, 
      archive_dir = archive_dir, 
      magnification = 25, 
      classifier_constant_name = class_constant, 
      classifier_increasing_name = class_increasing, 
      bemovi_extract_name = "bemovi_extract.mag.25.yml", 
      species_tracked = yaml::read_yaml(paste0(base, "parameter/bemovi.mag.25/bemovi_extract.mag.25.yml"))$species_tracked,
      output = out,
      mc.cores = params$cores
    )
  )
  system.time(
    classify_bemovi_archive( 
      timestamps = timestamps, 
      archive_dir = archive_dir, 
      magnification = 25, 
      classifier_constant_name = class_constant, 
      classifier_increasing_name = class_increasing, 
      bemovi_extract_name = "bemovi_extract.mag.25.non_cropped.yml", 
      species_tracked = yaml::read_yaml(paste0(base, "parameter/bemovi.mag.25/bemovi_extract.mag.25.non_cropped.yml"))$species_tracked,
      output = out,
      mc.cores = params$cores
    )
  )
  system.time(
    classify_bemovi_archive( 
      timestamps = timestamps, 
      archive_dir = archive_dir, 
      magnification = 25, 
      classifier_constant_name = class_constant, 
      classifier_increasing_name = class_increasing, 
      bemovi_extract_name = "bemovi_extract.mag.25.cropped.yml", 
      species_tracked = yaml::read_yaml(paste0(base, "parameter/bemovi.mag.25/bemovi_extract.mag.25.cropped.yml"))$species_tracked,
      output = out,
      mc.cores = params$cores
    )
  )
} else {
  message(
    "Directory ", out, "exists\n",
    "Skipping 'bemovi_mag_25'"
  )
}
```

### Clean Up Bemovi 25
```{r cleanup_bemovi_25}
unlink(pdir)
rm(pdir, class_constant, class_increasing, out, species_tracked)
```

## Add to database
Old timestamps will be removed and not be backed up.
```{r addRRD}
file.copy(org_db, bemovi_reclass_db)
system.time(
  add_reclassified_to_db(
    path = output, 
    db = bemovi_reclass_db, 
    remove_timestamps = NULL, #timestamps,
    backup_removed = FALSE
  )
)
```

## Add experiment specific tables
```{r addExptables, eval=FALSE, include=FALSE}
pdir <- tempfile()
dir.create(pdir, showWarnings = FALSE, recursive = TRUE)

experimental_design <- file.path(pdir, "experimental_design.csv")
download.file(
  paste0(base, "parameter/00.general.parameter/experimental_design.csv"), 
  destfile = experimental_design,
  mode = "wb"
)

compositions <- file.path(pdir, "compositions.csv")
download.file(
  paste0(base, "parameter/00.general.parameter/compositions.csv"), 
  destfile = compositions,
  mode = "wb"
)

light_decline_schedule <- file.path(pdir, "light_decline_schedule.csv")
download.file(
  paste0(base, "treatment/light_decline_schedule.csv"), 
  destfile = light_decline_schedule,
  mode = "wb"
)

immigration_schedule <- file.path(pdir, "immigration_schedule.csv")
download.file(
  paste0(base, "treatment/immigration_schedule.csv"), 
  destfile = immigration_schedule,
  mode = "wb"
)


add_experiment_tables(
  db = db, 
  composition = compositions, 
  experimetal_design = experimental_design,
  light_decline_schedule = light_decline_schedule,
  immigration_schedule = immigration_schedule,
  overwrite = TRUE
)

unlink(pdir)
rm(pdir, compositions, experimental_design)
```

# DONE - Reclassification of individual bottles and possibly timestamps
## Flowcam Bottle `b_02`
Bottle `b_02` was contaminated and needs to be classified separately. All timestamps will be classified using the same classifier.

### Set Bottle and range of timestamps
```{r bot_after_until}
bott <- "b_02"
after <- 20220128
until <- 30000000
```

### Set output path
```{r output_path_b}
out <- file.path(output, paste0("flowcam_", bott, "_", format(after, scientific = FALSE), "_", format(until, scientific = FALSE)))
```

### Determine timestamps
All available after `20220504` data will be reclassified and are determined below based on the archived data.
```{r prepare_flowcam_b}
timestamps <- list.files(
  path = file.path(archive_dir, "LEEF.archived.data", "LEEF", "3.archived.data", "extracted"), 
  pattern = "^LEEF\\.fast\\.flowcam\\.",
  recursive = FALSE, 
  full.names = FALSE
)
timestamps <- gsub("^LEEF\\.fast\\.flowcam\\.", "", timestamps)
timestamps <- as.integer(timestamps)

timestamps <- timestamps[(timestamps >= after) & (timestamps <= until)]
timestamps
```


### Prepare Flowcam
```{r prepare_flowcam}
pdir <- tempfile()
dir.create(pdir, showWarnings = FALSE, recursive = TRUE)

class_constant <- file.path(pdir, "class_constant.rds")
download.file(
  paste0(base, "parameter/flowcam/svm_flowcam_classifiers_B02_contaminated_20221226_MergedData.rds"), 
  destfile = class_constant,
  mode = "wb"
)

class_increasing <- file.path(pdir, "class_increasing.rds")
download.file(
  paste0(base, "parameter/flowcam/svm_flowcam_classifiers_B02_contaminated_20221226_MergedData.rds"), 
  destfile = class_increasing,
  mode = "wb"
)
```

### Classify Flowcam
```{r classify_flowcam}
if (!file.exists(out)) {
  message("Classifying flowcam...")
  system.time(
    classify_flowcam_archive(
      archive_dir = archive_dir, 
      timestamps = timestamps, 
      algae_traits_name = "algae_traits_filtered.rds", 
      classifier_constant_name = class_constant, 
      classifier_increasing_name = class_increasing, 
      species_tracked = yaml::read_yaml(paste0(base, "parameter/flowcam/flowcam.yml"))$species_tracked,
      output = out,
      mc.cores = params$cores,
      bottle = bott
    )
  )
} else {
  message(
    "Directory ", out, "exists\n",
    "skipping Flowcam."
  )
}
```

### Clean Up Flowcam
```{r cleanup_flowcam}
unlink(pdir)
rm(class_constant, class_increasing)
```

### Add to database
#### Delete entries from database
```{r}
file.copy(bemovi_reclass_db, flowcam_reclass_db)

message("Deleting entries...")
delete_density_sql <- paste0(
  "DELETE ",
  "FROM flowcam__algae_density ", 
  "WHERE bottle = '", bott, "' AND timestamp >= ", format(after, scientific = FALSE), " AND timestamp <= ", format(until, scientific = FALSE)
)
delete_traits_sql <- paste0(
  "DELETE ",
  "FROM flowcam__algae_traits ", 
  "WHERE bottle = '", bott, "' AND timestamp >= ", format(after, scientific = FALSE), " AND timestamp <= ", format(until, scientific = FALSE)
)

conn <- DBI::dbConnect(
  drv = RSQLite::SQLite(),
  db = flowcam_reclass_db
)

message("Executing query '", delete_density_sql, "`...")
rd <- DBI::dbExecute(conn, delete_density_sql)
message("   ", rd, " rows deleted.")

message("Executing query '", delete_traits_sql, "`...")
rd <- DBI::dbExecute(conn, delete_traits_sql)
message("   ", rd, " rows deleted.")

DBI::dbDisconnect(conn)
```

#### Add new entries to database 
```{r addRRD}
message("Adding directory '", basename(out), "' to the database")

files <- list.files(out, full.names = TRUE)
tables <- paste0(
  basename("flowcam"), "__",
  sapply( files, function(f) {strsplit(basename(f), "\\.")[[1]][[1]]})
)
names(tables) <- NULL

system.time(
  add_to_db(
    fns = files,
    tables = tables,
    db = flowcam_reclass_db,
    remove_timestamps = NULL,
    check_timestamps = FALSE,
    backup_removed = FALSE
  )
)
rm(out)
```

# TODO - Set species to 0 which were mis-classified

This section has been devaloped by Uriah 

## Preparations
```{r species_to_0_setup}

# Inf --------------------------------------------------------------------

# Developed by Uriah

# Setup -------------------------------------------------------------------


### Density data and co.

file.copy(flowcam_reclass_db, bemovi_filter_db)

options(RRDdb = bemovi_filter_db)

# densities <- db_read_table(table = "density") %>%
#   dplyr::filter(day < 1000,
#                 !(species %in% c("Didinium","airbubbles","Debris",
#                                  "DigestedAlgae","OtherCiliate", "HNA", "LNA", "MNA", "algae",
#                                  "Small_unidentified","ColpidiumVacuoles", "Debris_and_other")),
#                 !(species=="Cryptomonas" & measurement!="flowcam"),
#                 !(species=="Dexiostoma" & measurement=="flowcam"),
#                 !(species=="Coleps_irchel" & measurement=="flowcam"),
#                 !(species=="Colpidium" & measurement=="flowcam"),
#                 !(species=="Loxocephallus" & measurement=="flowcam"),
#                 !(species=="Tetrahymena" & measurement=="flowcam"),
#   ) %>%
#   dplyr::collect() %>%
#   dplyr::arrange(day)

exp_design <- db_read_table(table = "experimetal_design") %>% dplyr::collect()
compositions <- db_read_table(table = "composition") %>% dplyr::collect()
```

## bemovi

In the code below the videos the remove are defined. They are then removed
in the various morph_mvt tables and the densities are recalculated. Species
that could be present but are not are set to 0.
These densities are then used to overwrite the previous densities values.
This is done at 25x and 16x




### Preparation 25x
```{r species_to_0_bemovi_25}

videos_movingback <- c("20211013_00058", "20211103_00037", "20211105_00066",
                       "20211117_00016", "20211124_00007", "20211210_00031",
                       "20211210_00085", "20220105_00034", "20220119_00058",
                       "20220119_00070", "20220119_00088", "20220124_00085",
                       "20220131_00013", "20220131_00034", "20220131_00043",
                       "20220131_00082", "20220131_00085", "20220131_00088",
                       "20220207_00013", "20220228_00004", "20220228_00019",
                       "20220228_00067", "20220304_00034", "20220408_00088",
                       "20220413_00052", "20220502_00076", "20220509_00086",
                       "20220516_00076", "20220523_00058", "20220601_00064",
                       "20220617_00082", "20220620_00076", "20220622_00076",
                       "20220624_00055", "20220629_00082", "20210924_00001",
                       "20210929_00001", "20210929_00064", "20211001_00012",
                       "20211001_00028", "20211008_00021", "20211013_00076",
                       "20211015_00077", "20211022_00088", "20211105_00022",
                       "20211105_00024", "20211203_00016", "20211203_00040",
                       "20211203_00061", "20211215_00043", "20220107_00054",
                       "20220119_00010", "20220126_00025", "20220131_00079",
                       "20220202_00043", "20220204_00061", "20220204_00067",
                       "20220207_00010", "20220207_00022", "20220304_00076",
                       "20220427_00061", "20220525_00010", "20220530_00016",
                       "20220601_00050", "20220620_00010", "20220620_00073",
                       "20220622_00010", "20220622_00073", "20220704_00055",
                       "20211129_00077", "20211203_00003", "20211203_00009",
                       "20211208_00002", "20220126_00046", "20220126_00049",
                       "20220204_00002", "20220207_00020", "20220207_00052",
                       "20211001_00054", "20211001_00066", "20211001_00069",
                       "20211001_00079", "20211022_00042", "20211022_00067",
                       "20211027_00007", "20211101_00081", "20211129_00001",
                       "20211203_00050", "20211220_00035", "20220126_00054",
                       "20220126_00067", "20220126_00068", "20220207_00031",
                       "20220207_00043", "20220207_00054")

bottle <- strsplit(videos_movingback, split='_', fixed=TRUE)
bottle <- as.numeric(unlist(purrr::map(bottle, 2)))
bottle <- ceiling(bottle/3)
bottle <- ifelse(bottle<10, paste0("b_0",bottle), paste0("b_",bottle))

timestamp_movingback <- unlist(purrr::map(strsplit(videos_movingback, split='_', fixed=TRUE),1))

moving_background <- data.frame(bottle = bottle,
                                timestamp = (timestamp_movingback))
```

### Preparation 16x
```{r species_to_0_bemovi_16}

videos_to_remove_16 <- c("20210924_00108", "20211020_00133", "20211025_00140",
                         "20211101_00151", "20211105_00129", "20211108_00121",
                         "20220131_00156" ,"20220525_00135")

timestamp_movingback16 <- unlist(purrr::map(strsplit(videos_to_remove_16, split='_', fixed=TRUE),1))

bottle16 <- strsplit(videos_to_remove_16, split='_', fixed=TRUE)
bottle16 <- as.numeric(unlist(purrr::map(bottle16, 2))) - 90
bottle16 <- ceiling(bottle16/3)
bottle16 <- ifelse(bottle16<10, paste0("b_0",bottle16), paste0("b_",bottle16))

moving_background16 <- data.frame(bottle = bottle16,
                                  timestamp = (timestamp_movingback16))

```

### Calculating new densities

#### bemovi_mag_25__morph_mvt

```{r species_to_0_bemovi_25_morph_mvt}

species.tracked <- c(
  "Paramecium_bursaria", 
  "Coleps_irchel",
  "Colpidium",
  "Paramecium_caudatum", 
  "Euplotes",
  "Stylonychia2"
)
meas <- "bemovi_mag_25"
extrapolation.factor <- 23.367
cropping.factor <- 1

morph25_list <- apply(moving_background, 1, function(row){
  sql = paste0("
                SELECT *
                FROM 'bemovi_mag_25__morph_mvt'
                WHERE timestamp == '", row["timestamp"],
               "' AND bottle == '", row["bottle"], "';")

  read_sql(sql = sql)
})

morph25 <- do.call("rbind", morph25_list) %>%
  dplyr::filter(!(file %in% videos_movingback))

morph25_density <- CalculateDensities(morph25, meas)
morph25_density <- SetNotFoundSpeciesTo0(morph25_density, moving_background, meas, exp_design, compositions, species.tracked)
```

#### bemovi_mag_25__morph_mvt_cropped

```{r species_to_0_bemovi_25_morph_mvt_cropped}

species.tracked <- c(
  "Dexiostoma",
  "Tetrahymena",
  "Loxocephallus"
)
meas <- "bemovi_mag_25_cropped"
extrapolation.factor <- 23.367
cropping.factor <- 4

morph25_cropped_list <- apply(moving_background, 1, function(row){
  sql = paste0("
                SELECT *
                FROM 'bemovi_mag_25__morph_mvt_cropped'
                WHERE timestamp == '", row["timestamp"],
               "' AND bottle == '", row["bottle"], "';")

  read_sql(sql = sql)
})

morph25_cropped <- do.call("rbind", morph25_cropped_list) %>%
  dplyr::filter(!(file %in% videos_movingback))

morph25_cropped_density <- CalculateDensities(morph25_cropped, meas)
morph25_cropped_density <- SetNotFoundSpeciesTo0(
  morph25_cropped_density, 
  moving_background, 
  meas, exp_design, 
  compositions, 
  species.tracked
)
```


#### bemovi_mag_25__morph_mvt_non_cropped

```{r species_to_0_bemovi_25_morph_mvt_non_cropped}
species.tracked <- c("Dexiostoma","Tetrahymena","Loxocephallus")
meas <- "bemovi_mag_25_non_cropped"
extrapolation.factor <- 23.367
cropping.factor <- 1

morph25_non_cropped_list <- apply(moving_background, 1, function(row){
  sql = paste0("
                SELECT *
                FROM 'bemovi_mag_25__morph_mvt_non_cropped'
                WHERE timestamp == '", row["timestamp"],
               "' AND bottle == '", row["bottle"], "';")

  read_sql(sql = sql)
})

morph25_non_cropped <- do.call("rbind", morph25_non_cropped_list) %>%
  dplyr::filter(!(file %in% videos_movingback))

morph25_non_cropped_density <- CalculateDensities(morph25_non_cropped, meas)
morph25_non_cropped_density <- SetNotFoundSpeciesTo0(
  morph25_non_cropped_density, 
  moving_background, 
  meas, exp_design, 
  compositions, 
  species.tracked
)
```

#### bemovi_mag_16__morph_mvt

```{r species_to_0_bemovi_16_morph_mvt}
species.tracked <- c("Paramecium_bursaria", "Coleps_irchel","Colpidium","Paramecium_caudatum", "Euplotes","Stylonychia2")
meas <- "bemovi_mag_16"
extrapolation.factor <- 10.044
cropping.factor <- 1

morph16_list <- apply(moving_background16, 1, function(row){
  sql = paste0("
                SELECT *
                FROM 'bemovi_mag_16__morph_mvt'
                WHERE timestamp == '", row["timestamp"],
               "' AND bottle == '", row["bottle"], "';")

  read_sql(sql = sql)
})

morph16 <- do.call("rbind", morph16_list) %>%
  dplyr::filter(!(file %in% videos_to_remove_16))

morph16_density <- CalculateDensities(morph16, meas)
morph16_density <- SetNotFoundSpeciesTo0(
  morph16_density, 
  moving_background16, 
  meas, 
  exp_design, 
  compositions, 
  species.tracked
)
```


### Update RRD
#### Delete moving videos from `__morph_mvt` and `__mean_densities_per_ml...` tables in RRD database

```{r delete_bemovi_moving, options}
conn <- DBI::dbConnect(
  drv = RSQLite::SQLite(),
  db = bemovi_filter_db
)
DBI::dbBegin(conn)

## morph_mvt

message("Deleting bemovi 25 entries from morph_mvt ...")
delete_sql <- paste0(
  "DELETE ",
  "FROM bemovi_mag_25__morph_mvt ", 
  "WHERE file IN (", paste0('"', videos_movingback, '"', collapse = ", "), ");"
)
message("Executing query '", delete_sql, "`...")
rd <- DBI::dbExecute(conn, delete_sql)
message("   ", rd, " rows deleted.")

message("Deleting bemovi 25 entries from morph_mvt_cropped ...")
delete_sql <- paste0(
  "DELETE ",
  "FROM bemovi_mag_25__morph_mvt_cropped ", 
  "WHERE file IN (", paste0('"', videos_movingback, '"', collapse = ", "), ");"
)
message("Executing query '", delete_sql, "`...")
rd <- DBI::dbExecute(conn, delete_sql)
message("   ", rd, " rows deleted.")

message("Deleting bemovi 25 entries from morph_mvt_non_cropped ...")
delete_sql <- paste0(
  "DELETE ",
  "FROM bemovi_mag_25__morph_mvt_non_cropped ", 
  "WHERE file IN (", paste0('"', videos_movingback, '"', collapse = ", "), ");"
)
message("Executing query '", delete_sql, "`...")
rd <- DBI::dbExecute(conn, delete_sql)
message("   ", rd, " rows deleted.")

message("Deleting bemovi 16 entries from morph_mvt ...")
delete_sql <- paste0(
  "DELETE ",
  "FROM bemovi_mag_16__morph_mvt ", 
  "WHERE file IN (", paste0('"', videos_to_remove_16, '"', collapse = ", "), ");"
)
message("Executing query '", delete_sql, "`...")
rd <- DBI::dbExecute(conn, delete_sql)
message("   ", rd, " rows deleted.")


## density

message("Deleting bemovi 25 entries from mean_density_per_ml ...")
delete_sql <- paste0(
  "DELETE ",
  "FROM bemovi_mag_25__mean_density_per_ml",
  " WHERE (",
  paste0(
    apply(
      moving_background, 
      1,
      function(row){
        paste0("timestamp == '", row["timestamp"],"' AND bottle == '", row["bottle"], "'")
      }
    ),
    collapse = ") OR ("
  ),
  ")"
)
message("Executing query '", delete_sql, "`...")
rd <- DBI::dbExecute(conn, delete_sql)
message("   ", rd, " rows deleted.")
  
message("Deleting bemovi 25 entries from mean_density_per_ml_cropped ...")
delete_sql <- paste0(
  "DELETE ",
  "FROM bemovi_mag_25__mean_density_per_ml_cropped",
  " WHERE (",
  paste0(
    apply(
      moving_background, 
      1,
      function(row){
        paste0("timestamp == '", row["timestamp"],"' AND bottle == '", row["bottle"], "'")
      }
    ),
    collapse = ") OR ("
  ),
  ")"
)
message("Executing query '", delete_sql, "`...")
rd <- DBI::dbExecute(conn, delete_sql)
message("   ", rd, " rows deleted.")

message("Deleting bemovi 25 entries from mean_density_per_ml_non_cropped ...")
delete_sql <- paste0(
  "DELETE ",
  "FROM bemovi_mag_25__mean_density_per_ml_non_cropped",
  " WHERE (",
  paste0(
    apply(
      moving_background, 
      1,
      function(row){
        paste0("timestamp == '", row["timestamp"],"' AND bottle == '", row["bottle"], "'")
      }
    ),
    collapse = ") OR ("
  ),
  ")"
)
message("Executing query '", delete_sql, "`...")
rd <- DBI::dbExecute(conn, delete_sql)
message("   ", rd, " rows deleted.")

message("Deleting bemovi 16 entries from mean_density_per_ml ...")
delete_sql <- paste0(
  "DELETE ",
  "FROM bemovi_mag_16__mean_density_per_ml",
  " WHERE (",
  paste0(
    apply(
      moving_background, 
      1,
      function(row){
        paste0("timestamp == '", row["timestamp"],"' AND bottle == '", row["bottle"], "'")
      }
    ),
    collapse = ") OR ("
  ),
  ")"
)
message("Executing query '", delete_sql, "`...")
rd <- DBI::dbExecute(conn, delete_sql)
message("   ", rd, " rows deleted.")

## close

DBI::dbCommit(conn)
DBI::dbDisconnect(conn)
```

#### Add updated densities to RRD database
```{r delete_bemovi_moving}
conn <- DBI::dbConnect(
  drv = RSQLite::SQLite(),
  db = bemovi_filter_db
)


DBI::dbBegin(conn)

DBI::dbWriteTable(
  conn,
  name = "bemovi_mag_25__mean_density_per_ml",
  value = morph25_density[,-which(names(morph25_density) == "numberOfVideos")],
  overwrite = FALSE,
  append = TRUE
)

DBI::dbWriteTable(
  conn,
  name = "bemovi_mag_25__mean_density_per_ml_cropped",
  value = morph25_cropped_density[,-which(names(morph25_cropped_density) == "numberOfVideos")],
  overwrite = FALSE,
  append = TRUE
)

DBI::dbWriteTable(
  conn,
  name = "bemovi_mag_25__mean_density_per_ml_non_cropped",
  value = morph25_non_cropped_density[,-which(names(morph25_non_cropped_density) == "numberOfVideos")],
  overwrite = FALSE,
  append = TRUE
)

DBI::dbWriteTable(
  conn,
  name = "bemovi_mag_16__mean_density_per_ml",
  value = morph16_density[,-which(names(morph16_density) == "numberOfVideos")],
  overwrite = FALSE,
  append = TRUE
)


DBI::dbCommit(conn)
      
## close

DBI::dbDisconnect(conn)
```


## Flowcam

The code below recalculates the densities after filtering Stau1 so that only
particles are kept with high confidence that they are indeed Stau1.


```{r species_to_0_bemovi_25_morph_mvt}
file.copy(bemovi_filter_db, flowcam_filter_db)

options(RRDdb = flowcam_filter_db)

sql <-  paste0(
  "
    SELECT *
    FROM 'flowcam__algae_traits'
    WHERE species == 'Staurastrum1' AND species_probability > 0.9;
  "
)
  
stau1traits <- read_sql(sql = sql) %>%
  group_by(bottle)

# extrapolation.factor <- 1/0.3 # I think 0.3ml were imaged

densityStau1 <- stau1traits %>%
  group_by(
    date_flowcam,
    species,
    bottle,
    composition,
    temperature,
    incubator,
    volume_imaged,
    dilution_factor,
    richness,
    timestamp
  ) %>%
  summarize(count=n()) %>%
  mutate(density = count * (dilution_factor / volume_imaged))

# Set not found to 0

temp <- tidyr::expand_grid(
  timestamp = unique(stau1traits$timestamp),
  bottle = unique(stau1traits$bottle),
  species = "Staurastrum1"
)

densityStau1 <- full_join(densityStau1, temp) %>%
  mutate(
    count = ifelse(is.na(count),0,count),
    density = ifelse(is.na(density),0,density)
  )
```


### Update RRD
Delete from traits and add re-calcul;ated ones.

```{r label, eval=FALSE}

conn <- DBI::dbConnect(
  drv = RSQLite::SQLite(),
  db = db
)
DBI::dbBegin(conn)


message("Deleting flowcam entries from flowcam__algae_traits ...")
delete_sql <- paste0(
  "DELETE ",
  "FROM flowcam__algae_traits ",
  "WHERE (species == \"Staurastrum1\" AND species_probability <= 0.9)"
)
message("Executing query '", delete_sql, "`...")
rd <- DBI::dbExecute(conn, delete_sql)
message("   ", rd, " rows deleted.")

message("Deleting flowcam densities from RRD ...")
delete_sql <- paste0(
  "DELETE ",
  "FROM flowcam__algae_density ",
  "WHERE (species == \"Staurastrum1\"); "
)
message("Executing query '", delete_sql, "`...")
rd <- DBI::dbExecute(conn, delete_sql)
message("   ", rd, " rows deleted.")


message("Adding flowcam densities to RRD ...")
DBI::dbWriteTable(
  conn,
  name = "flowcam__algae_density",
  value = densityStau1,
  overwrite = FALSE,
  append = TRUE
)
message("   ", nrow(densityStau1), " rows added")

## close

DBI::dbCommit(conn)
DBI::dbDisconnect(conn)
```




# Do a final vacuuming into new database
Vacuuming the database will take some time!

To vacuum the sqlite database, i.e. recover the space from the deletion of rows, please run the following command in the directory where the database is located:

```{r echo = FALSE}
db_vac <- gsub("\\.sqlite$", ".vacuumed.sqlite", db)
cat(paste0("sqlite3 \"./", basename(db), "\" 'VACUUM main INTO \"", basename(db_vac), "\"'"))

```

# Create Diagnostic Report
```{r createDiagReport}
report_diagnostic(
  db = flowcam_filter_db,  
  template = "LEEF_1",
  suffix = "reclassified", 
  format = "html"
)
```

