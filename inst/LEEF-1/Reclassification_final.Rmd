---
title: "Reclassification"
author: "Rainer M Krug"
date: "06/05/2022"
output:
  html_document:
    dev: png
    fig_width: 10
    fig_height: 12
    toc: true
    toc_float: true
    toc_collapsed: true
    code_folding: hide
params:
  output_dir: "~/RRD.Reclassification_final/"
  base: "https://github.com/LEEF-UZH/LEEF.parameter/raw/v1.7.1/"
  db: "~/RRD.Reclassification_final/LEEF.RRD.sqlite"
  archive_dir: "/Volumes/LEEF-1_archive/"
  cores: 14
---

```{r setup_reclass, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  eval = TRUE,
  message = TRUE,
  warning = TRUE
)
library("LEEF.analysis")
```

# Preparation
## Set Base to use
This reclassification is based on the classifiers as in the repo at the base URL which speicifies the repo and the reference / tag which should be used for this reclassification
```{r}
base <- params$base
```

## Set output path
```{r output_path}
output <-  params$output_dir
dir.create(output, recursive = TRUE, showWarnings = FALSE)
```

## Set database
```{r output_path}
db <- params$db
```

## Set Archive Directory
Make sure, that the S3 LEEF archive is mounted and you know the path to the archive as it is needed.

```{r setArchive}

archive_dir <- params$archive_dir
if (!file.exists(archive_dir)){
  stop(
    "Archive directory '", archive_dir, "' does not exist!\n",
    "Probably not mounted?" 
  )
}
if (!file.exists(file.path(archive_dir, "LEEF.archived.data", "LEEF", "3.archived.data", "extracted"))){
  stop(
    "Archive directory is not valid! \n",
    "It does not contain the folder '", file.path(archive_dir, "LEEF.archived.data", "LEEF", "3.archived_data", "extracted"), "'.\n",
    "Probably not mounted?" 
  )
}
```


## Set timestamps
All available data will be reclassified. Therefore, the timestamps are determined for each method below based on the archived data.

# Reclassification of all timestamps

## Flowcam

### Prepare Flowcam
```{r prepare_flowcam}
pdir <- tempfile()
dir.create(pdir, showWarnings = FALSE, recursive = TRUE)

class_constant <- file.path(pdir, "class_constant.rds")
download.file(
  paste0(base, "parameter/flowcam/svm_flowcam_classifiers_20221226_MergedData.rds"), 
  destfile = class_constant,
  mode = "wb"
)

class_increasing <- file.path(pdir, "class_increasing.rds")
download.file(
  paste0(base, "parameter/flowcam/svm_flowcam_classifiers_20221226_MergedData.rds"), 
  destfile = class_increasing,
  mode = "wb"
)

timestamps <- list.files(
  path = file.path(archive_dir, "LEEF.archived.data", "LEEF", "3.archived.data", "extracted"), 
  pattern = "^LEEF\\.fast\\.flowcam\\.",
  recursive = FALSE, 
  full.names = FALSE
)
timestamps <- gsub("^LEEF\\.fast\\.flowcam\\.", "", timestamps)
```

### Classify Flowcam
```{r classify_flowcam}
out <- file.path(output, "flowcam")
if (!file.exists(out)) {
  message("Classifying flowcam...")
  system.time(
    classify_flowcam_archive(
      archive_dir = archive_dir, 
      timestamps = timestamps, 
      algae_traits_name = "algae_traits_filtered.rds", 
      classifier_constant_name = class_constant, 
      classifier_increasing_name = class_increasing, 
      species_tracked = yaml::read_yaml(paste0(base, "parameter/flowcam/flowcam.yml"))$species_tracked,
      output = out,
      mc.cores = params$cores
    )
  )
} else {
  message(
    "Directory ", out, "exists\n",
    "skipping Flowcam."
  )
}
```

### Clean Up Flowcam
```{r cleanup_flowcam}
unlink(pdir)
rm(class_constant, class_increasing, out)
```

## Bemovi magnification 16
### Prepare Bemovi 16
```{r prepare_bemovi_16}
pdir <- tempfile()
dir.create(pdir, showWarnings = FALSE, recursive = TRUE)

class_constant <- file.path(pdir, "class_constant.rds")
download.file(
  paste0(base, "parameter/bemovi.mag.16/svm_video_classifiers_16x_20220706_MergedData.rds"), 
  destfile = class_constant,
  mode = "wb"
)

class_increasing <- file.path(pdir, "class_increasing.rds")
download.file(
  paste0(base, "/parameter/bemovi.mag.16/svm_video_classifiers_16x_20220706_MergedData.rds"), 
  destfile = class_increasing,
  mode = "wb"
)

timestamps <- list.files(
  path = file.path(archive_dir, "LEEF.archived.data", "LEEF", "3.archived.data", "extracted"), 
  pattern = "^LEEF\\.bemovi\\.mag\\.16\\.bemovi\\.",
  recursive = FALSE, 
  full.names = FALSE
)
timestamps <- gsub("^LEEF\\.bemovi\\.mag\\.16\\.bemovi\\.", "", timestamps)
```

### Classify `bemovi_extract.mag.16.yml`
```{r classify_bemovi_16}
out <- file.path(output, "bemovi_mag_16")
if (!file.exists(out)) {
  message("Classifying bemovi_extract.mag.16")
  system.time(
    classify_bemovi_archive( 
      timestamps = timestamps, 
      archive_dir = archive_dir, 
      magnification = 16, 
      classifier_constant_name = class_constant, 
      classifier_increasing_name = class_increasing, 
      bemovi_extract_name = "bemovi_extract.mag.16.yml", 
      species_tracked = yaml::read_yaml(paste0(base, "parameter/bemovi.mag.16/bemovi_extract.mag.16.yml"))$species_tracked,
      output = out,
      mc.cores = params$cores
    )
  )
} else {
  message(
    "Directory ", out, " exists\n",
    "Skipping 'bemovi_extract.mag.16.'"
  )
}
```

### Clean Up Bemovi 16
```{r cleanup_bemovi_16}
unlink(pdir)
rm(pdir, class_constant, class_increasing, out)
```

## Bemovi magnification 25
### Prepare Bemovi 25
```{r prepare_bemovi_25}
pdir <- tempfile()
dir.create(pdir, showWarnings = FALSE, recursive = TRUE)

class_constant <- file.path(pdir, "class_constant.rds")
download.file(
  paste0(base, "parameter/bemovi.mag.25/svm_video_classifiers_25x_20220706_MergedData.rds"), 
  destfile = class_constant,
  mode = "wb"
)

class_increasing <- file.path(pdir, "class_increasing.rds")
download.file(
  paste0(base, "parameter/bemovi.mag.25/svm_video_classifiers_25x_20220706_MergedData.rds"), 
  destfile = class_increasing,
  mode = "wb"
)

timestamps <- list.files(
  path = file.path(archive_dir, "LEEF.archived.data", "LEEF", "3.archived.data", "extracted"), 
  pattern = "^LEEF\\.bemovi\\.mag\\.25\\.bemovi\\.",
  recursive = FALSE, 
  full.names = FALSE
)
timestamps <- gsub("^LEEF\\.bemovi\\.mag\\.25\\.bemovi\\.", "", timestamps)
```

### Classify `bemovi_mag.25` 
```{r classify_bemovi_25}
out <- file.path(output, "bemovi_mag_25")
if (!file.exists(out)) {
  system.time(
    classify_bemovi_archive( 
      timestamps = timestamps, 
      archive_dir = archive_dir, 
      magnification = 25, 
      classifier_constant_name = class_constant, 
      classifier_increasing_name = class_increasing, 
      bemovi_extract_name = "bemovi_extract.mag.25.yml", 
      species_tracked = yaml::read_yaml(paste0(base, "parameter/bemovi.mag.25/bemovi_extract.mag.25.yml"))$species_tracked,
      output = out,
      mc.cores = params$cores
    )
  )
  system.time(
    classify_bemovi_archive( 
      timestamps = timestamps, 
      archive_dir = archive_dir, 
      magnification = 25, 
      classifier_constant_name = class_constant, 
      classifier_increasing_name = class_increasing, 
      bemovi_extract_name = "bemovi_extract.mag.25.non_cropped.yml", 
      species_tracked = yaml::read_yaml(paste0(base, "parameter/bemovi.mag.25/bemovi_extract.mag.25.non_cropped.yml"))$species_tracked,
      output = out,
      mc.cores = params$cores
    )
  )
  system.time(
    classify_bemovi_archive( 
      timestamps = timestamps, 
      archive_dir = archive_dir, 
      magnification = 25, 
      classifier_constant_name = class_constant, 
      classifier_increasing_name = class_increasing, 
      bemovi_extract_name = "bemovi_extract.mag.25.cropped.yml", 
      species_tracked = yaml::read_yaml(paste0(base, "parameter/bemovi.mag.25/bemovi_extract.mag.25.cropped.yml"))$species_tracked,
      output = out,
      mc.cores = params$cores
    )
  )
} else {
  message(
    "Directory ", out, "exists\n",
    "Skipping 'bemovi_mag_25'"
  )
}
```

### Clean Up Bemovi 25
```{r cleanup_bemovi_25}
unlink(pdir)
rm(pdir, class_constant, class_increasing, out, species_tracked)
```

## Add to database
Old timestamps will be removed and not be backed up.
```{r addRRD}
system.time(
  add_reclassified_to_db(
    path = output, 
    db = db, 
    remove_timestamps = NULL, #timestamps,
    backup_removed = FALSE
  )
)
```

## Add experiment specific tables
```{r addExptables, eval=FALSE, include=FALSE}
pdir <- tempfile()
dir.create(pdir, showWarnings = FALSE, recursive = TRUE)

experimental_design <- file.path(pdir, "experimental_design.csv")
download.file(
  paste0(base, "parameter/00.general.parameter/experimental_design.csv"), 
  destfile = experimental_design,
  mode = "wb"
)

compositions <- file.path(pdir, "compositions.csv")
download.file(
  paste0(base, "parameter/00.general.parameter/compositions.csv"), 
  destfile = compositions,
  mode = "wb"
)

light_decline_schedule <- file.path(pdir, "light_decline_schedule.csv")
download.file(
  paste0(base, "treatment/light_decline_schedule.csv"), 
  destfile = light_decline_schedule,
  mode = "wb"
)

immigration_schedule <- file.path(pdir, "immigration_schedule.csv")
download.file(
  paste0(base, "treatment/immigration_schedule.csv"), 
  destfile = immigration_schedule,
  mode = "wb"
)


add_experiment_tables(
  db = db, 
  composition = compositions, 
  experimetal_design = experimental_design,
  light_decline_schedule = light_decline_schedule,
  immigration_schedule = immigration_schedule,
  overwrite = TRUE
)

unlink(pdir)
rm(pdir, compositions, experimental_design)
```

# Reclassification of individual bottles and possibly timestamps
## Flowcam Bottle `b_02`
Bottle `b_02` was contaminated and needs to be classified separately. All timestamps will be classified using the same classifier.

### Set Bottle and range of timestamps
```{r bot_after_until}
bott <- "b_02"
after <- 20220128
until <- 30000000
```

### Set output path
```{r output_path_b}
out <- file.path(output, paste0("flowcam_", bott, "_", format(after, scientific = FALSE), "_", format(until, scientific = FALSE)))
```

### Determine timestamps
All available after `20220504` data will be reclassified and are determined below based on the archived data.
```{r prepare_flowcam_b}
timestamps <- list.files(
  path = file.path(archive_dir, "LEEF.archived.data", "LEEF", "3.archived.data", "extracted"), 
  pattern = "^LEEF\\.fast\\.flowcam\\.",
  recursive = FALSE, 
  full.names = FALSE
)
timestamps <- gsub("^LEEF\\.fast\\.flowcam\\.", "", timestamps)
timestamps <- as.integer(timestamps)

timestamps <- timestamps[(timestamps >= after) & (timestamps <= until)]
timestamps
```


### Prepare Flowcam
```{r prepare_flowcam}
pdir <- tempfile()
dir.create(pdir, showWarnings = FALSE, recursive = TRUE)

class_constant <- file.path(pdir, "class_constant.rds")
download.file(
  paste0(base, "parameter/flowcam/svm_flowcam_classifiers_B02_contaminated_20221226_MergedData.rds"), 
  destfile = class_constant,
  mode = "wb"
)

class_increasing <- file.path(pdir, "class_increasing.rds")
download.file(
  paste0(base, "parameter/flowcam/svm_flowcam_classifiers_B02_contaminated_20221226_MergedData.rds"), 
  destfile = class_increasing,
  mode = "wb"
)
```

### Classify Flowcam
```{r classify_flowcam}
if (!file.exists(out)) {
  message("Classifying flowcam...")
  system.time(
    classify_flowcam_archive(
      archive_dir = archive_dir, 
      timestamps = timestamps, 
      algae_traits_name = "algae_traits_filtered.rds", 
      classifier_constant_name = class_constant, 
      classifier_increasing_name = class_increasing, 
      species_tracked = yaml::read_yaml(paste0(base, "parameter/flowcam/flowcam.yml"))$species_tracked,
      output = out,
      mc.cores = params$cores,
      bottle = bott
    )
  )
} else {
  message(
    "Directory ", out, "exists\n",
    "skipping Flowcam."
  )
}
```

### Clean Up Flowcam
```{r cleanup_flowcam}
unlink(pdir)
rm(class_constant, class_increasing)
```

### Add to database
#### Delete entries from database
```{r}
message("Deleting entries...")
delete_density_sql <- paste0(
  "DELETE ",
  "FROM flowcam__algae_density ", 
  "WHERE bottle = '", bott, "' AND timestamp >= ", format(after, scientific = FALSE), " AND timestamp <= ", format(until, scientific = FALSE)
)
delete_traits_sql <- paste0(
  "DELETE ",
  "FROM flowcam__algae_traits ", 
  "WHERE bottle = '", bott, "' AND timestamp >= ", format(after, scientific = FALSE), " AND timestamp <= ", format(until, scientific = FALSE)
)

conn <- DBI::dbConnect(
  drv = RSQLite::SQLite(),
  db = db
)
message("Executing query '", delete_density_sql, "`...")
rd <- DBI::dbExecute(conn, delete_density_sql)
message("   ", rd, " rows deleted.")

message("Executing query '", delete_traits_sql, "`...")
rd <- DBI::dbExecute(conn, delete_traits_sql)
message("   ", rd, " rows deleted.")
DBI::dbDisconnect(conn)
```

#### Add new entries to database 
```{r addRRD}
message("Adding directory '", basename(out), "' to the database")

files <- list.files(out, full.names = TRUE)
tables <- paste0(
  basename("flowcam"), "__",
  sapply( files, function(f) {strsplit(basename(f), "\\.")[[1]][[1]]})
)
names(tables) <- NULL

system.time(
  add_to_db(
    fns = files,
    tables = tables,
    db = db,
    remove_timestamps = NULL,
    check_timestamps = FALSE,
    backup_removed = FALSE
  )
)
rm(out)
```

# Set species to 0 which were mis-classified

Developed by Uriah

## Setup
```{r species_to_0_setup}

# Inf --------------------------------------------------------------------

# Developed by Uriah

# Setup -------------------------------------------------------------------


### Density data and co.

options(RRDdb = db)
densities <- db_read_table(table = "density") %>%
  dplyr::filter(day < 1000,
                !(species %in% c("Didinium","airbubbles","Debris",
                                 "DigestedAlgae","OtherCiliate", "HNA", "LNA", "MNA", "algae",
                                 "Small_unidentified","ColpidiumVacuoles", "Debris_and_other")),
                !(species=="Cryptomonas" & measurement!="flowcam"),
                !(species=="Dexiostoma" & measurement=="flowcam"),
                !(species=="Coleps_irchel" & measurement=="flowcam"),
                !(species=="Colpidium" & measurement=="flowcam"),
                !(species=="Loxocephallus" & measurement=="flowcam"),
                !(species=="Tetrahymena" & measurement=="flowcam"),
  ) %>%
  dplyr::collect() %>%
  dplyr::arrange(day)

exp_design <- db_read_table(table = "experimetal_design") %>% dplyr::collect()
compositions <- db_read_table(table = "composition") %>% dplyr::collect()


```

## bemovi

In the code below the videos the remove are defined. They are then removed
in the various morph_mvt tables and the densities are recalculated. Species
that could be present but are not are set to 0.
These densities are then used to overwrite the previous densities values.
This is done at 25x and 16x

Note --------------------------------------------------------------------

After this also the video ciliate traits should be overwritten in the RRD
after filtering out the videos
I haven't done it here, can you do it?



The code to read in and filter should be something like this:

```{r, eval = FALSE}
bemovi_mag_25__morph_mvt <- db_read_table(table = "bemovi_mag_25__morph_mvt") %>%
  dplyr::filter(!(file %in% videos_movingback))

bemovi_mag_25__morph_mvt_cropped <- db_read_table(table = "bemovi_mag_25__morph_mvt_cropped") %>%
  dplyr::filter(!(file %in% videos_movingback))

bemovi_mag_25__morph_mvt_non_cropped <- db_read_table(table = "bemovi_mag_25__morph_mvt_non_cropped") %>%
  dplyr::filter(!(file %in% videos_movingback))

bemovi_mag_16__morph_mvt <- db_read_table(table = "bemovi_mag_16__morph_mvt") %>%
  dplyr::filter(!(file %in% videos_to_remove_16)) ##note the different file!!!
```


### Preparation 25x
```{r species_to_0_bemovi_25}

videos_movingback <- c("20211013_00058", "20211103_00037", "20211105_00066",
                       "20211117_00016", "20211124_00007", "20211210_00031",
                       "20211210_00085", "20220105_00034", "20220119_00058",
                       "20220119_00070", "20220119_00088", "20220124_00085",
                       "20220131_00013", "20220131_00034", "20220131_00043",
                       "20220131_00082", "20220131_00085", "20220131_00088",
                       "20220207_00013", "20220228_00004", "20220228_00019",
                       "20220228_00067", "20220304_00034", "20220408_00088",
                       "20220413_00052", "20220502_00076", "20220509_00086",
                       "20220516_00076", "20220523_00058", "20220601_00064",
                       "20220617_00082", "20220620_00076", "20220622_00076",
                       "20220624_00055", "20220629_00082", "20210924_00001",
                       "20210929_00001", "20210929_00064", "20211001_00012",
                       "20211001_00028", "20211008_00021", "20211013_00076",
                       "20211015_00077", "20211022_00088", "20211105_00022",
                       "20211105_00024", "20211203_00016", "20211203_00040",
                       "20211203_00061", "20211215_00043", "20220107_00054",
                       "20220119_00010", "20220126_00025", "20220131_00079",
                       "20220202_00043", "20220204_00061", "20220204_00067",
                       "20220207_00010", "20220207_00022", "20220304_00076",
                       "20220427_00061", "20220525_00010", "20220530_00016",
                       "20220601_00050", "20220620_00010", "20220620_00073",
                       "20220622_00010", "20220622_00073", "20220704_00055",
                       "20211129_00077", "20211203_00003", "20211203_00009",
                       "20211208_00002", "20220126_00046", "20220126_00049",
                       "20220204_00002", "20220207_00020", "20220207_00052",
                       "20211001_00054", "20211001_00066", "20211001_00069",
                       "20211001_00079", "20211022_00042", "20211022_00067",
                       "20211027_00007", "20211101_00081", "20211129_00001",
                       "20211203_00050", "20211220_00035", "20220126_00054",
                       "20220126_00067", "20220126_00068", "20220207_00031",
                       "20220207_00043", "20220207_00054")

bottle <- strsplit(videos_movingback, split='_', fixed=TRUE)
bottle <- as.numeric(unlist(purr::map(bottle, 2)))
bottle <- ceiling(bottle/3)
bottle <- ifelse(bottle<10, paste0("b_0",bottle), paste0("b_",bottle))

timestamp_movingback <- unlist(purr::map(strsplit(videos_movingback, split='_', fixed=TRUE),1))

moving_background <- data.frame(bottle = bottle,
                                timestamp = (timestamp_movingback))
```

### Preparation 16x
```{r species_to_0_bemovi_16}

videos_to_remove_16 <- c("20210924_00108", "20211020_00133", "20211025_00140",
                         "20211101_00151", "20211105_00129", "20211108_00121",
                         "20220131_00156" ,"20220525_00135")

timestamp_movingback16 <- unlist(purr::map(strsplit(videos_to_remove_16, split='_', fixed=TRUE),1))

bottle16 <- strsplit(videos_to_remove_16, split='_', fixed=TRUE)
bottle16 <- as.numeric(unlist(purr::map(bottle16, 2))) - 90
bottle16 <- ceiling(bottle16/3)
bottle16 <- ifelse(bottle16<10, paste0("b_0",bottle16), paste0("b_",bottle16))

moving_background16 <- data.frame(bottle = bottle16,
                                  timestamp = (timestamp_movingback16))

```

### Removing videos, recalculating densities and overwriting ######

#### bemovi_mag_25__morph_mvt ######

```{r species_to_0_bemovi_25_morph_mvt}

species.tracked <- c(
  "Paramecium_bursaria", 
  "Coleps_irchel",
  "Colpidium",
  "Paramecium_caudatum", 
  "Euplotes",
  "Stylonychia2"
)
meas <- "bemovi_mag_25"
extrapolation.factor <- 23.367
cropping.factor <- 1

morph25_list <- apply(moving_background, 1, function(row){
  sql = paste0("
                SELECT *
                FROM 'bemovi_mag_25__morph_mvt'
                WHERE timestamp == '", row["timestamp"],
               "' AND bottle == '", row["bottle"], "';")

  read_sql(sql = sql)
})

morph25 <- do.call("rbind", morph25_list) %>%
  dplyr::filter(!(file %in% videos_movingback))

morph25_density <- CalculateDensities(morph25, meas)
morph25_density <- SetNotFoundSpeciesTo0(morph25_density, moving_background, meas, exp_design, compositions, species.tracked)
```

#### bemovi_mag_25__morph_mvt_cropped ######

```{r species_to_0_bemovi_25_morph_mvt_cropped}

species.tracked <- c(
  "Dexiostoma",
  "Tetrahymena",
  "Loxocephallus"
)
meas <- "bemovi_mag_25_cropped"
extrapolation.factor <- 23.367
cropping.factor <- 4

morph25_cropped_list <- apply(moving_background, 1, function(row){
  sql = paste0("
                SELECT *
                FROM 'bemovi_mag_25__morph_mvt_cropped'
                WHERE timestamp == '", row["timestamp"],
               "' AND bottle == '", row["bottle"], "';")

  read_sql(sql = sql)
})

morph25_cropped <- do.call("rbind", morph25_cropped_list) %>%
  dplyr::filter(!(file %in% videos_movingback))

morph25_cropped_density <- CalculateDensities(morph25_cropped, meas)
morph25_cropped_density <- SetNotFoundSpeciesTo0(
  morph25_cropped_density, 
  moving_background, 
  meas, exp_design, 
  compositions, 
  species.tracked
)
```


### bemovi_mag_25__morph_mvt_non_cropped ######

```{r species_to_0_bemovi_25_morph_mvt_non_cropped}
species.tracked <- c("Dexiostoma","Tetrahymena","Loxocephallus")
meas <- "bemovi_mag_25_non_cropped"
extrapolation.factor <- 23.367
cropping.factor <- 1

morph25_non_cropped_list <- apply(moving_background, 1, function(row){
  sql = paste0("
                SELECT *
                FROM 'bemovi_mag_25__morph_mvt_non_cropped'
                WHERE timestamp == '", row["timestamp"],
               "' AND bottle == '", row["bottle"], "';")

  read_sql(sql = sql)
})

morph25_non_cropped <- do.call("rbind", morph25_non_cropped_list) %>%
  dplyr::filter(!(file %in% videos_movingback))

morph25_non_cropped_density <- CalculateDensities(morph25_non_cropped, meas)
morph25_non_cropped_density <- SetNotFoundSpeciesTo0(
  morph25_non_cropped_density, 
  moving_background, 
  meas, exp_design, 
  compositions, 
  species.tracked
)
```

### bemovi_mag_16__morph_mvt ######

```{r species_to_0_bemovi_16_morph_mvt}
species.tracked <- c("Paramecium_bursaria", "Coleps_irchel","Colpidium","Paramecium_caudatum", "Euplotes","Stylonychia2")
meas <- "bemovi_mag_16"
extrapolation.factor <- 10.044
cropping.factor <- 1

morph16_list <- apply(moving_background16, 1, function(row){
  sql = paste0("
                SELECT *
                FROM 'bemovi_mag_16__morph_mvt'
                WHERE timestamp == '", row["timestamp"],
               "' AND bottle == '", row["bottle"], "';")

  read_sql(sql = sql)
})

morph16 <- do.call("rbind", morph16_list) %>%
  dplyr::filter(!(file %in% videos_to_remove_16))

morph16_density <- CalculateDensities(morph16, meas)
morph16_density <- SetNotFoundSpeciesTo0(
  morph16_density, 
  moving_background16, 
  meas, 
  exp_design, 
  compositions, 
  species.tracked
)
```

### bind new densities together ######

```{r species_to_0_bemovi_bind}

new_densities <- rbind(morph25_density,morph25_cropped_density,morph25_non_cropped_density, morph16_density) %>%
  dplyr::filter(!(species %in% c("Cryptomonas", "Debris_and_other")))
```
### overwrite the new densities in the main density data.frame ######

```{r species_to_0_bemovi_densities}

densities$rownumber <- 1:nrow(densities)

old_densities <- right_join(densities,new_densities[,-4])

rownumbers <- old_densities$rownumber

densities[rownumbers,"density"] <- NA

densities <- full_join(densities,new_densities,
                       by = c("timestamp", "bottle", "measurement", "species", "composition")) %>%
  mutate(density.x = case_when(is.na(density.x)~density.y,
                               T ~ density.x)) %>%
  rename(density=density.x) %>%
  select(-density.y)
```



## Flowcam

The code below recalculates the densities after filtering Stau1 so that only
particles are kept with high confidence that they are indeed Stau1.
What is not done but needs to be done is to also overwrite the algae_traits
table so that these particles are excluded there. I haven't done it because
the table is so big and it takes a while to load it. Can you do it?
The code to read and filter should simply be (commented out):

```{r, eval = FALSE}
algae_traits <- db_read_table(table = "flowcam__algae_traits") %>%
  filter(case_when(species=="Staurastrum1" ~ species_probability > 0.9,
                   T ~ species_probability > 0))
```

```{r species_to_0_bemovi_25_morph_mvt}
timestamps <- sort(as.character(unique(densities$timestamp)))

stau1traits <- mclapply(timestamps, function(ts){
  sql = paste0("
             SELECT *
             FROM 'flowcam__algae_traits'
             WHERE timestamp == '", ts,
               "' AND species == '", "Staurastrum1", "';")

  read_sql(sql = sql)
}, mc.cores = detectCores()-2)

stau1traits <- do.call("rbind", stau1traits)

stau1traits <- stau1traits %>%
  group_by(bottle) %>%
  filter(species_probability > 0.9)

extrapolation.factor <- 1/0.3 # I think 0.3ml were imaged

densityStau1 <- stau1traits %>%
  group_by(timestamp, bottle, species) %>%
  summarize(count=n()) %>%
  mutate(density = count * extrapolation.factor)

temp <- expand_grid(timestamp = timestamps,
                    bottle = unique(stau1traits$bottle),
                    species = "Staurastrum1")

densityStau1 <- full_join(densityStau1, temp) %>%
  mutate(count = ifelse(is.na(count),0,count),
         density = ifelse(is.na(density),0,density))

densities <- densities %>%
  mutate(density = ifelse(species=="Staurastrum1", NA, density))

densities <- full_join(densities,densityStau1,
                       by = c("timestamp", "bottle", "species")) %>%
  mutate(density.x = case_when(is.na(density.x)~density.y,
                               T ~ density.x)) %>%
  rename(density=density.x) %>%
  select(-density.y, -count)
```










# Do a final vacuuming into new database
Vacuuming the database will take some time!

To vacuum the sqlite database, i.e. recover the space from the deletion of rows, please run the following command in the directory where the database is located:

```{r echo = FALSE}
db_vac <- gsub("\\.sqlite$", ".vacuumed.sqlite", db)
cat(paste0("sqlite3 \"./", basename(db), "\" 'VACUUM main INTO \"", basename(db_vac), "\"'"))

```

# Create Diagnostic Report
```{r createDiagReport}
report_diagnostic(
  db = db,  
  template = "LEEF_1",
  suffix = "reclassified", 
  format = "html"
)
```

