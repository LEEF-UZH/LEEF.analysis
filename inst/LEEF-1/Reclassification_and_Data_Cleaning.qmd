---
title: "Reclassification and Data Cleaning"
author: "Rainer M Krug"
date: "24/04/2022"

output:
  html_document:
    dev: png
    fig_width: 10
    fig_height: 12
    toc: true
    toc_float: true
    toc_collapsed: true
    code_folding: hide  
    embed-resources: true
params:
  version_tag: "v1.8.5"
  base: "https://github.com/LEEF-UZH/LEEF.parameter/raw/"
  output_dir: "~/RRD.Reclassification_final/"
  db: "~/RRD.Reclassification_final/LEEF.RRD.sqlite"
  archive_dir: "/Volumes/LEEF-1_archive/"
  pre_processed_folder: "/Volumes/LEEF-1_archive/LEEF.archived.data/LEEF/3.archived.data/pre_processed/"
  extracted_dir: "/Volumes/LEEF-1_archive/LEEF.archived.data/LEEF/3.archived.data/extracted/"
  toc: "/Volumes/LEEF/0.TOC/LEEF-1/toc.rds"
  min_FSC.A: 2
  cores: 7
  remove_all:
    - airbubbles
    - OtherCiliate
    - Debris_and_other
    - Cryptomonas
  remove_flowcam:
    - Dexiostoma
    - Coleps_irchel
    - Colpidium
    - Loxocephallus
    - Tetrahymena
  keep_flowcytometer:
    - bacteria
    - algae
---

# Setup
1. Set Base to use
This reclassification is based on the classifiers as in the repo at the base URL which speicifies the repo and the reference / tag which should be used for this reclassification
2. Set output path
3. Set database
4. Set Archive Directory
Make sure, that the S3 LEEF archive is mounted and you know the path to the archive as it is needed.


```{r setup_reclass, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  eval = TRUE,
  message = TRUE,
  warning = TRUE
)
library("LEEF.analysis")
library(dplyr)

## 1.
base <- paste0(params$base, params$version_tag, "/")

## 2.
dir.create(params$output_dir, recursive = TRUE, showWarnings = FALSE)

## 3.


db_name <- function(
    iteration,
    db_org = params$db,
    version_tag = params$version_tag,
    temp = FALSE
){
  db_name <- gsub(".sqlite", paste0(".", version_tag, "_", iteration, ".sqlite"), db_org)
  if (temp){
    db_name <- paste0(db_name, ".tmp")
  }
  return(db_name)
}

## 4.
if (!file.exists(params$archive_dir)){
  stop(
    "This is not a problem when not reclassifying! \n",
    "Archive directory '", params$archive_dir, "' does not exist!\n",
    "Probably not mounted?" 
  )
}
if (!file.exists(params$extracted_dir)){
  stop(
    "This is not a problem when not reclassifying! \n",
    "Archive directory is not valid! \n",
    "It does not contain the folder '", params$extracted_dir, "'.\n",
    "Probably not mounted?" 
  )
}

if (file.exists(params$db)) {
  stop(params$db, " exists and will not be overwritten!\n", "If you want to re-generate, please rename the database or delete it!")
} else {
  RRD_new(params$db, LEEF = "LEEF-1")
  ## Adding of General Parameter tables
  pdir <- tempfile()
  dir.create(pdir, showWarnings = FALSE, recursive = TRUE)
  
  composition <- file.path(pdir, "compositions.csv")
  download.file(
    paste0(base, "parameter/00.general.parameter/compositions.csv"), 
    destfile = composition,
    mode = "wb"
  )
  
  experimental_design <- file.path(pdir, "experimental_design.csv")
  download.file(
    paste0(base, "parameter/00.general.parameter/experimental_design.csv"), 
    destfile = experimental_design,
    mode = "wb"
  )
  
  immigration_schedule <- file.path(pdir, "immigration_schedule.csv")
  download.file(
    paste0(base, "treatment/immigration_schedule.csv"), 
    destfile = immigration_schedule,
    mode = "wb"
  )
  
  light_decline_schedule <- file.path(pdir, "light_decline_schedule.csv")
  download.file(
    paste0(base, "treatment/light_decline_schedule.csv"), 
    destfile = light_decline_schedule,
    mode = "wb"
  )
  
  
  suppressMessages(  
    add_to_db(
      fns = composition,
      db = params$db,
      tables = "composition",
      remove_timestamps = NULL,
      check_timestamps = FALSE,
      backup_removed = TRUE
    )
  )
  
  suppressMessages(  
    add_to_db(
      fns = experimental_design,
      db = params$db,
      tables = "experimental_design",
      remove_timestamps = NULL,
      check_timestamps = FALSE,
      backup_removed = TRUE
    )
  )
  
  suppressMessages(  
    add_to_db(
      fns = immigration_schedule,
      db = params$db,
      tables = "immigration_schedule",
      remove_timestamps = NULL,
      check_timestamps = FALSE,
      backup_removed = TRUE
    )
  )
  
  suppressMessages(  
    add_to_db(
      fns = light_decline_schedule,
      db = params$db,
      tables = "light_decline_schedule",
      remove_timestamps = NULL,
      check_timestamps = FALSE,
      backup_removed = TRUE
    )
  )
  
  unlink(pdir)
  rm(composition, experimental_design, immigration_schedule, light_decline_schedule)
  
}
```

# 1. Re-calculations for all timestamps
## Reclassification of Flowcam

### Prepare Flowcam
```{r prepare_flowcam}
pdir <- tempfile()
dir.create(pdir, showWarnings = FALSE, recursive = TRUE)

class_constant <- file.path(pdir, "class_constant.rds")
download.file(
  paste0(base, "parameter/flowcam/svm_flowcam_classifiers_20221226_MergedData.rds"), 
  destfile = class_constant,
  mode = "wb"
)

class_increasing <- file.path(pdir, "class_increasing.rds")
download.file(
  paste0(base, "parameter/flowcam/svm_flowcam_classifiers_20221226_MergedData.rds"), 
  destfile = class_increasing,
  mode = "wb"
)

timestamps <- list.files(
  path = params$extracted_dir, 
  pattern = "^LEEF\\.fast\\.flowcam\\.",
  recursive = FALSE, 
  full.names = FALSE
)
timestamps <- gsub("^LEEF\\.fast\\.flowcam\\.", "", timestamps)
```

### Classify Flowcam up to 20220704
```{r classify_flowcam}


out <- file.path(params$output_dir, "flowcam")
if (!file.exists(out)) {
  message("Classifying flowcam...")
  system.time(
    classify_flowcam_archive(
      archive_dir = params$archive_dir, 
      timestamps = timestamps[as.numeric(timestamps) <= 20220704], 
      algae_traits_name = "algae_traits_filtered.rds", 
      classifier_constant_name = class_constant, 
      classifier_increasing_name = class_increasing, 
      species_tracked = yaml::read_yaml(paste0(base, "parameter/flowcam/flowcam.yml"))$species_tracked,
      output = out,
      mc.cores = params$cores
    )
  )
} else {
  message(
    "Directory ", out, "exists\n",
    "skipping Flowcam."
  )
}
```


### Clean Up Flowcam
```{r cleanup_flowcam}
unlink(pdir)
rm(class_constant, class_increasing, out)
```

## Flowcam Bottle `b_02`
Bottle `b_02` was contaminated and needs to be classified separately. All timestamps will be classified using the same classifier.

### Set Bottle and range of timestamps
```{r bot_after_until}
bott <- "b_02"
after <- 20220128
until <- 30000000
```

### Set output path
```{r output_path_b}
out <- file.path(params$output_dir, "flowcam.b_02")
```

### Determine timestamps
All available after `20220504` data will be reclassified and are determined below based on the archived data.
```{r flowcam_timestamps}
timestamps <- list.files(
  path = params$extracted_dir, 
  pattern = "^LEEF\\.fast\\.flowcam\\.",
  recursive = FALSE, 
  full.names = FALSE
)
timestamps <- gsub("^LEEF\\.fast\\.flowcam\\.", "", timestamps)
timestamps <- as.integer(timestamps)

timestamps <- timestamps[(timestamps >= after) & (timestamps <= until)]
timestamps
```


### Prepare Flowcam
```{r prepare_flowcam_2}
pdir <- tempfile()
dir.create(pdir, showWarnings = FALSE, recursive = TRUE)

class_constant <- file.path(pdir, "class_constant.rds")
download.file(
  paste0(base, "parameter/flowcam/svm_flowcam_classifiers_B02_contaminated_20221226_MergedData.rds"), 
  destfile = class_constant,
  mode = "wb"
)

class_increasing <- file.path(pdir, "class_increasing.rds")
download.file(
  paste0(base, "parameter/flowcam/svm_flowcam_classifiers_B02_contaminated_20221226_MergedData.rds"), 
  destfile = class_increasing,
  mode = "wb"
)
```

### Classify Flowcam b_02 up to 20220704
```{r classify_flowcam_1}
message("Classifying flowcam...")
system.time(
  classify_flowcam_archive(
    archive_dir = params$archive_dir, 
    timestamps = timestamps[as.numeric(timestamps) <= 20220704], 
    algae_traits_name = "algae_traits_filtered.rds", 
    classifier_constant_name = class_constant, 
    classifier_increasing_name = class_increasing, 
    species_tracked = yaml::read_yaml(paste0(base, "parameter/flowcam/flowcam.yml"))$species_tracked,
    output = out,
    mc.cores = params$cores,
    bottle = bott
  )
)
```

### Clean Up Flowcam
```{r cleanup_flowcam_1}
unlink(pdir)
rm(class_constant, class_increasing)
```

### Merge `flowcam.b_02` into `flowcam`
```{r}
#| label: merge_flowcams
#| 

b02 <- list.files(
  file.path(params$output_dir, "flowcam.b_02")
)

pbmcapply::pbmclapply(
  sample(b02),
  function(fn){
    file.path(params$output_dir, "flowcam", fn) |>
      readRDS() |>
      dplyr::filter(bottle != "b_02") |>
      dplyr::bind_rows(
        readRDS( file.path(params$output_dir, "flowcam.b_02", fn) ) |>
          mutate(timestamp = as.character(timestamp))
      ) |>
    saveRDS(file = file.path(params$output_dir, "flowcam", fn))
  },
  mc.preschedule = FALSE, 
  mc.cores = params$cores
)

```


### Adding density=0 for some special cases

```{r man_correction}
cont_timestamp <- 20220128
cont_bottle <- "b_02"

fns <- list.files(
  path = file.path(params$output_dir, "flowcam"), 
  pattern = "density",
  full.names = TRUE,
  recursive = FALSE
)

pbmcapply::pbmclapply(
  fns,
  function(fn){
    ts <- strsplit(basename(fn), "\\.")[[1]][2] |>
      as.numeric()
    
    x <- readRDS(fn)
    if (ts <= cont_timestamp) {
      templ <- x[x$bottle == cont_bottle,][1,]
      templ$density <- 0
      
      templ$species <- "Desmodesmus"
      x <- rbind(x, templ)
      
      templ$species <- "DesmodesmusClumps"
      x <- rbind(x, templ)
    }
    ###### HERE BEGIN
    x_list <- split(
      x = x,
      f = x$bottle,
      drop = TRUE
    )
    
    for (i in seq_along(x_list)) {
      templ <- x_list[[i]][1,]
      templ$density <- 0
      templ$count <- 0
      sp <- unique(x_list[[i]]$species)
      if ("Chlamydomonas" %in% sp){
        if (!("ChlamydomonasClumps" %in% sp)){
          templ$species <- "ChlamydomonasClumps"
          x_list[[i]] <- rbind(x_list[[i]], templ)
        }
      }
      if ("Desmodesmus" %in% sp){
        if (!("DesmodesmusClumps" %in% sp)){
          templ$species <- "DesmodesmusClumps"
          x_list[[i]] <- rbind(x_list[[i]], templ) |> 
            dplyr::mutate(Date_Flowcam = data.table::as.IDate(Date_Flowcam))
        }
      }
    }
    
    x <- do.call("rbind", x_list)
    ###### HERE END
    saveRDS(x, fn)
  },
  mc.cores = params$cores, 
  mc.preschedule = FALSE
)
```
### Flowcam remove species not needed

```{r}
#| label: flowcam_remove_species
#| 

fns <- list.files(
  file.path(params$output_dir, "flowcam"),
  recursive = FALSE,
  full.names = TRUE
)

pbmcapply::pbmclapply(
  fns,
  function(fn){
    x <- readRDS(fn) |>
      dplyr::filter(!(species %in% c(params$remove_all, params$remove_flowcam)))
    if ("airbubbles" %in% unique(x$species)) {browser()}
    unlink(fn)
    saveRDS(x, file = fn)
  }, 
  mc.preschedule = FALSE,
  mc.cores = params$cores
)
```

## Bemovi 16 - Reclassification
### Prepare Bemovi 16
```{r prepare_bemovi_16}
pdir <- tempfile()
dir.create(pdir, showWarnings = FALSE, recursive = TRUE)

class_constant <- file.path(pdir, "class_constant.rds")
download.file(
  paste0(base, "parameter/bemovi.mag.16/svm_video_classifiers_16x_20220706_MergedData.rds"), 
  destfile = class_constant,
  mode = "wb"
)

class_increasing <- file.path(pdir, "class_increasing.rds")
download.file(
  paste0(base, "/parameter/bemovi.mag.16/svm_video_classifiers_16x_20220706_MergedData.rds"), 
  destfile = class_increasing,
  mode = "wb"
)

timestamps <- list.files(
  path = params$extracted_dir, 
  pattern = "^LEEF\\.bemovi\\.mag\\.16\\.bemovi\\.",
  recursive = FALSE, 
  full.names = FALSE
)
timestamps <- gsub("^LEEF\\.bemovi\\.mag\\.16\\.bemovi\\.", "", timestamps)
```

### Classify `bemovi_extract.mag.16.yml`
```{r classify_bemovi_16}
moving_background <- c(
  "20210924_00108", "20211020_00133", "20211025_00140",
  "20211101_00151", "20211105_00129", "20211108_00121",
  "20220131_00156" ,"20220525_00135"
)

out <- file.path(params$output_dir, "bemovi_mag_16")

if (!file.exists(out)) {
  message("Classifying bemovi_extract.mag.16")
  system.time(
    suppressMessages(
      classify_bemovi_archive( 
        timestamps = timestamps, 
        archive_dir = params$archive_dir, 
        magnification = 16, 
        classifier_constant_name = class_constant, 
        classifier_increasing_name = class_increasing, 
        bemovi_extract_name = "bemovi_extract.mag.16.yml", 
        species_tracked = yaml::read_yaml(paste0(base, "parameter/bemovi.mag.16/bemovi_extract.mag.16.yml"))$species_tracked,
        output = out,
        exclude_videos = moving_background,
        mc.cores = params$cores
      )
    )
  )
} else {
  message(
    "Directory ", out, " exists\n",
    "Skipping 'bemovi_extract.mag.16.'"
  )
}
```

### Clean Up Bemovi 16
```{r cleanup_bemovi_16}
unlink(pdir)
rm(pdir, class_constant, class_increasing, out, moving_background)
```

### Bemovi 16 remove species not needed

```{r}
#| label: bemovi_16_remove_species
#| 

fns <- list.files(
  file.path(params$output_dir, "bemovi_mag_16"),
  recursive = FALSE,
  full.names = TRUE
)

pbmcapply::pbmclapply(
  fns,
  function(fn){
    x <- readRDS(fn) |>
      dplyr::filter(!(species %in% params$remove_all))
    unlink(fn)
    saveRDS(x, file = fn)
  }, 
  mc.preschedule = FALSE,
  mc.cores = params$cores
)
```

## Bemovi 25 - Reclassification of 
### Prepare Bemovi 25
```{r prepare_bemovi_25}
pdir <- tempfile()
dir.create(pdir, showWarnings = FALSE, recursive = TRUE)

class_constant <- file.path(pdir, "class_constant.rds")
download.file(
  paste0(base, "parameter/bemovi.mag.25/svm_video_classifiers_25x_20220706_MergedData.rds"), 
  destfile = class_constant,
  mode = "wb"
)

class_increasing <- file.path(pdir, "class_increasing.rds")
download.file(
  paste0(base, "parameter/bemovi.mag.25/svm_video_classifiers_25x_20220706_MergedData.rds"), 
  destfile = class_increasing,
  mode = "wb"
)

timestamps <- list.files(
  path = params$extracted_dir, 
  pattern = "^LEEF\\.bemovi\\.mag\\.25\\.bemovi\\.",
  recursive = FALSE, 
  full.names = FALSE
)
timestamps <- gsub("^LEEF\\.bemovi\\.mag\\.25\\.bemovi\\.", "", timestamps)
```

### Classify `bemovi_mag.25` excluding "20220622" (duplicates of "20220620")

```{r classify_bemovi_25}
excl <- c("20220622")

moving_background <- c(
  "20211013_00058", "20211103_00037", "20211105_00066",
  "20211117_00016", "20211124_00007", "20211210_00031",
  "20211210_00085", "20220105_00034", "20220119_00058",
  "20220119_00070", "20220119_00088", "20220124_00085",
  "20220131_00013", "20220131_00034", "20220131_00043",
  "20220131_00082", "20220131_00085", "20220131_00088",
  "20220207_00013", "20220228_00004", "20220228_00019",
  "20220228_00067", "20220304_00034", "20220408_00088",
  "20220413_00052", "20220502_00076", "20220509_00086",
  "20220516_00076", "20220523_00058", "20220601_00064",
  "20220617_00082", "20220620_00076", "20220622_00076",
  "20220624_00055", "20220629_00082", "20210924_00001",
  "20210929_00001", "20210929_00064", "20211001_00012",
  "20211001_00028", "20211008_00021", "20211013_00076",
  "20211015_00077", "20211022_00088", "20211105_00022",
  "20211105_00024", "20211203_00016", "20211203_00040",
  "20211203_00061", "20211215_00043", "20220107_00054",
  "20220119_00010", "20220126_00025", "20220131_00079",
  "20220202_00043", "20220204_00061", "20220204_00067",
  "20220207_00010", "20220207_00022", "20220304_00076",
  "20220427_00061", "20220525_00010", "20220530_00016",
  "20220601_00050", "20220620_00010", "20220620_00073",
  "20220622_00010", "20220622_00073", "20220704_00055",
  "20211129_00077", "20211203_00003", "20211203_00009",
  "20211208_00002", "20220126_00046", "20220126_00049",
  "20220204_00002", "20220207_00020", "20220207_00052",
  "20211001_00054", "20211001_00066", "20211001_00069",
  "20211001_00079", "20211022_00042", "20211022_00067",
  "20211027_00007", "20211101_00081", "20211129_00001",
  "20211203_00050", "20211220_00035", "20220126_00054",
  "20220126_00067", "20220126_00068", "20220207_00031",
  "20220207_00043", "20220207_00054"
)

out <- file.path(params$output_dir, "bemovi_mag_25")
if (!file.exists(out)) {
  system.time(
    suppressMessages(
      classify_bemovi_archive( 
        timestamps = timestamps[!grepl(excl, timestamps)], 
        archive_dir = params$archive_dir, 
        magnification = 25, 
        classifier_constant_name = class_constant, 
        classifier_increasing_name = class_increasing, 
        bemovi_extract_name = "bemovi_extract.mag.25.yml", 
        species_tracked = yaml::read_yaml(paste0(base, "parameter/bemovi.mag.25/bemovi_extract.mag.25.yml"))$species_tracked,
        output = out,
        exclude_videos = moving_background,
        mc.cores = params$cores
      )
    )
  )
  system.time(
    suppressMessages(
      classify_bemovi_archive( 
        timestamps = timestamps[!grepl(excl, timestamps)], 
        archive_dir = params$archive_dir, 
        magnification = 25, 
        classifier_constant_name = class_constant, 
        classifier_increasing_name = class_increasing, 
        bemovi_extract_name = "bemovi_extract.mag.25.non_cropped.yml", 
        species_tracked = yaml::read_yaml(paste0(base, "parameter/bemovi.mag.25/bemovi_extract.mag.25.non_cropped.yml"))$species_tracked,
        output = out,
        exclude_videos = moving_background,
        mc.cores = params$cores
      )
    )
  )
  system.time(
    suppressMessages(
      classify_bemovi_archive( 
        timestamps = timestamps[!grepl(excl, timestamps)], 
        archive_dir = params$archive_dir, 
        magnification = 25, 
        classifier_constant_name = class_constant, 
        classifier_increasing_name = class_increasing, 
        bemovi_extract_name = "bemovi_extract.mag.25.cropped.yml", 
        species_tracked = yaml::read_yaml(paste0(base, "parameter/bemovi.mag.25/bemovi_extract.mag.25.cropped.yml"))$species_tracked,
        output = out,
        exclude_videos = moving_background,
        mc.cores = params$cores
      )
    )
  )
} else {
  message(
    "Directory ", out, "exists\n",
    "Skipping 'bemovi_mag_25'"
  )
}
```

### Clean Up Bemovi 25
```{r cleanup_bemovi_25}
unlink(pdir)
rm(pdir, class_constant, class_increasing, out, moving_background)
```


### Bemovi 25 remove species not needed

```{r}
#| label: bemovi_25_remove_species
#| 

fns <- list.files(
  file.path(params$output_dir, "bemovi_mag_25"),
  recursive = FALSE,
  full.names = TRUE
)

pbmcapply::pbmclapply(
  fns,
  function(fn){
    x <- readRDS(fn) |>
      dplyr::filter(!(species %in% params$remove_all))
    unlink(fn)
    saveRDS(x, file = fn)
  }, 
  mc.preschedule = FALSE,
  mc.cores = params$cores
)
```

## Exclusion of time series that are wrong classifications or only noise
```{r}

excl <- data.frame(
  bottles = c(
    "b_30", "b_02", "b_09", "b_02", "b_09", "b_14", 
    "b_23", "b_04", "b_07", "b_13", "b_07", "b_13", 
    "b_07", "b_13", "b_10", "b_21", "b_10", "b_21",
    "b_01", "b_11", "b_01", "b_11", "b_20", "b_28",
    "b_28", "b_22", "b_22", "b_27", "b_22", "b_22",
    "b_27", "b_03", "b_03", "b_06" ,"b_03", "b_06", 
    "b_03", "b_06", "b_03", "b_03", "b_06", "b_19", 
    "b_29", "b_19", "b_29", "b_19", "b_29", "b_19", 
    "b_29", "b_05", "b_24" ,"b_05", "b_24", "b_05",
    "b_24", "b_05", "b_24", "b_15", "b_12", "b_15", 
    "b_12", "b_15", "b_12", "b_15", "b_12", "b_15", 
    "b_16", "b_26" ,"b_16", "b_26", "b_16", "b_26", 
    "b_16", "b_16", "b_26", "b_05", "b_12", "b_15",
    "b_16", "b_24", "b_26", "b_08", "b_06", "b_26",
    "b_14", "b_25"
  ),
  
  species = c(
    "Tetrahymena",   "Tetrahymena",    "Tetrahymena",   "Euplotes",      "Euplotes",      "Loxocephallus",   
    "Euplotes",      "Colpidium",      "Loxocephallus", "Loxocephallus", "Dexiostoma",    "Dexiostoma",
    "Euplotes",      "Euplotes",       "Colpidium",     "Colpidium",     "Loxocephallus", "Loxocephallus", 
    "Tetrahymena",   "Tetrahymena",    "Loxocephallus", "Loxocephallus", "Tetrahymena",   "Tetrahymena",  
    "Colpidium",     "Colpidium",      "Dexiostoma",    "Dexiostoma",    "Stylonychia2",  "Euplotes", 
    "Euplotes",      "Staurastrum1",   "Tetrahymena",   "Tetrahymena",   "Colpidium",     "Colpidium",   
    "Loxocephallus", "Loxocephallus",  "Stylonychia2",  "Euplotes",      "Euplotes",      "Colpidium",   
    "Colpidium",     "Loxocephallus",  "Loxocephallus", "Dexiostoma",    "Dexiostoma",    "Euplotes",  
    "Euplotes",      "Tetrahymena",    "Tetrahymena",   "Colpidium",     "Colpidium",     "Loxocephallus",   
    "Loxocephallus", "Euplotes",       "Euplotes",      "Staurastrum1",  "Colpidium",     "Colpidium",   
    "Loxocephallus", "Loxocephallus",  "Dexiostoma",    "Dexiostoma",    "Euplotes",      "Euplotes",   
    "Colpidium",     "Colpidium",      "Loxocephallus", "Loxocephallus", "Dexiostoma",    "Dexiostoma",  
    "Stylonychia2",  "Euplotes",       "Euplotes",      "Staurastrum2",  "Staurastrum2",  "Staurastrum2", 
    "Staurastrum2",  "Staurastrum2",   "Staurastrum2",  "Tetrahymena",   "Stylonychia2",  "Stylonychia2",
    "Euplotes",      "Euplotes"
  ) 
)

excl$bottle_species <- paste0(excl$bottles, "_", excl$species)

fns <- c(
  list.files(
    path = file.path(params$output_dir, "bemovi_mag_16"),
    pattern = "morph|density",
    recursive = FALSE,
    full.names = TRUE
  ),
  list.files(
    path = file.path(params$output_dir, "bemovi_mag_25"),
    pattern = "morph|density",
    recursive = FALSE,
    full.names = TRUE
  ),
  list.files(
    path = file.path(params$output_dir, "flowcam"),
    pattern = "traits|density",
    recursive = FALSE,
    full.names = TRUE
  )
)


pbmcapply::pbmclapply(
  fns,
  function(fn){
    x <- readRDS(fn) |>
      dplyr::mutate(bottle_species = paste0(bottle, "_", species)) |>
      dplyr::filter(!(bottle_species %in% excl$bottle_species))
    
    x |>
      dplyr::select(-bottle_species) |>
      saveRDS(file = fn)
  },
  mc.cores = params$cores, 
  mc.preschedule = FALSE
)

rm(excl, fns)
```


## Flowcytometer

### Prepare Flowcytometer
```{r prepare_flowcytometer}
pdir <- tempfile()
dir.create(pdir, showWarnings = FALSE, recursive = TRUE)

gates_coordinates <- file.path(pdir, "gates_coordinates.csv")
download.file(
  paste0(base, "parameter/flowcytometer/gates_coordinates.csv"), 
  destfile = gates_coordinates,
  mode = "wb"
)

gates_coordinates_EAWAG_samples <-  file.path(pdir, "gates_coordinates_Eawag_samples.csv")
gates_coordinates <- file.path(pdir, "gates_coordinates_Eawag_samples.csv")
download.file(
  paste0(base, "parameter/flowcytometer/gates_coordinates_Eawag_samples.csv"), 
  destfile = gates_coordinates,
  mode = "wb"
)


metadata_flowcytometer <- file.path(pdir, "metadata_flowcytometer.csv")
download.file(
  paste0(base, "parameter/flowcytometer/metadata_flowcytometer.csv"), 
  destfile = metadata_flowcytometer,
  mode = "wb"
)


conv_FSCA_length <- file.path(pdir, "conv_FSCA_length")
download.file(
  paste0(base, "parameter/flowcytometer/conv_FSCA_length.csv"), 
  destfile = conv_FSCA_length,
  mode = "wb"
)
```

### Flowcytometer densities

Regate using H and re-calculate the densities
#### All Samples
```{r densities}

## Select all timestamps

timestamps <- list.files(
  path = params$extracted_dir, 
  pattern = "^LEEF\\.fast\\.flowcytometer\\.",
  recursive = FALSE, 
  full.names = FALSE
)
timestamps <- gsub("^LEEF\\.fast\\.flowcytometer\\.", "", timestamps)

density_flowcytometer_archive(
  extracted_dir = params$extracted_dir,
  gates_coordinates = read.csv(gates_coordinates),
  timestamps = timestamps,
  output = file.path(params$output_dir, "flowcytometer"),
  use_H = TRUE,
  min_FSC.A = params$min_FSC.A,
  log10_all = TRUE,
  particles = "bacteria",
  mc.cores = params$cores
)

```
#### TODO EAWAG Samples

Now process the EAWAG samples. the previous ones will be replaced, if they exist.

```{r densities_EAWAG}
## Select all timestamps

extracted_EAWAG <- gsub("LEEF.archived.data", "LEEF.EAWAG.archived.data", params$extracted_dir)
timestamps <- list.files(
  path = extracted_EAWAG, 
  pattern = "^LEEF\\.fast\\.flowcytometer\\.",
  recursive = FALSE, 
  full.names = FALSE
)
timestamps <- gsub("^LEEF\\.fast\\.flowcytometer\\.", "", timestamps)

density_flowcytometer_archive(
  extracted_dir = extracted_EAWAG,
  gates_coordinates = read.csv(gates_coordinates_EAWAG_samples),
  timestamps = timestamps,
  output = file.path(params$output_dir, "flowcytometer"),
  use_H = TRUE,
  min_FSC.A = params$min_FSC.A,
  log10_all = TRUE,
  particles = "bacteria",
  mc.cores = params$cores
)
```


### Trait Extraction Flowcytometer and Volume Calculation

#### All Samples
```{r biomass}
## Select all timestamps
timestamps <- list.files(
  path = params$extracted_dir, 
  pattern = "^LEEF\\.fast\\.flowcytometer\\.",
  recursive = FALSE, 
  full.names = FALSE
)
timestamps <- gsub("^LEEF\\.fast\\.flowcytometer\\.", "", timestamps)

extract_traits_flowcytometer_archive(
  extracted_dir = params$extracted_dir,
  gates_coordinates = read.csv(gates_coordinates),
  particles = "bacteria",
  use_H = TRUE,
  min_FSC.A = params$min_FSC.A,
  log10_all = TRUE, 
  timestamps = timestamps,
  output = file.path(params$output_dir, "flowcytometer_traits"),
  length_slope =  read.csv(conv_FSCA_length)$slope,
  length_intercept =  read.csv(conv_FSCA_length)$intercept,
  mc.cores = params$cores
)
```

#### TODO EAWAG Samples

Now process the EAWAG samples. the previous ones will be replaced, if they exist.
```{r biomass_EAWAG}
## Select all timestamps
extracted_EAWAG <- gsub("LEEF.archived.data", "LEEF.EAWAG.archived.data", params$extracted_dir)

timestamps <- list.files(
  path = extracted_EAWAG, 
  pattern = "^LEEF\\.fast\\.flowcytometer\\.",
  recursive = FALSE, 
  full.names = FALSE
)
timestamps <- gsub("^LEEF\\.fast\\.flowcytometer\\.", "", timestamps)

extract_traits_flowcytometer_archive(
  extracted_dir = extracted_EAWAG,
  gates_coordinates = read.csv(gates_coordinates_EAWAG_samples),
  particles = "bacteria",
  use_H = TRUE,
  min_FSC.A = params$min_FSC.A,
  log10_all = TRUE,
  timestamps = timestamps,
  output = file.path(params$output_dir, "flowcytometer_traits"),
  length_slope =  read.csv(conv_FSCA_length)$slope,
  length_intercept =  read.csv(conv_FSCA_length)$intercept,
  mc.cores = params$cores, 
  wellid_keyword = "$SMNO"
)
```

#### Clean Up EAWAG
```{r cleanup_flowcytometer}
unlink(pdir)
rm(gates_coordinates, metadata_flowcytometer, gates_coordinates_EAWAG_samples, conv_FSCA_length)
```


### Flowcytometer select species needed
This can only be done in densities!

```{r}
#| label: flowcytometer_remove_categories
#| 

fns <- list.files(
  file.path(params$output_dir, "flowcytometer"),
  recursive = FALSE,
  full.names = TRUE
)

pbmcapply::pbmclapply(
  fns,
  function(fn){
    x <- readRDS(fn) |>
      dplyr::filter(species %in% params$keep_flowcytometer)
    unlink(fn)
    saveRDS(x, file = fn)
  }, 
  mc.cores = params$cores
)
```



## Add to database and create indices
Old timestamps will be removed and not be backed up.

```{r addRRD_copy}
file.copy(params$db, db_name(1, temp = TRUE))
```
```{r addRRD_b16}
## Bemovi_16

suppressMessages(
  add_reclassified_to_db(
    path = params$output_dir, 
    db = db_name(1, temp = TRUE), 
    remove_timestamps = NULL,
    backup_removed = FALSE,
    methods = "bemovi_mag_16"
  )
)
```
```{r addRRD_b25}
## Bemovi_25

suppressMessages(
  add_reclassified_to_db(
    path = params$output_dir, 
    db = db_name(1, temp = TRUE), 
    remove_timestamps = NULL,
    backup_removed = FALSE,
    methods = "bemovi_mag_25"
  )
)
```
```{r addRRD_fc}
## flowcam

suppressMessages(
  add_reclassified_to_db(
    path = params$output_dir, 
    db = db_name(1, temp = TRUE), 
    remove_timestamps = NULL,
    backup_removed = FALSE,
    methods = "flowcam"
  )
)
```

```{r addRRD_fcydens}
## Flowcytometer Densities

fns_dens <- list.files(
  path =  file.path(params$output_dir, "flowcytometer"), 
  pattern = "^flowcytometer_density\\..*\\.rds",
  recursive = FALSE, 
  full.names = TRUE
)

suppressMessages(
  add_to_db(
    fns_dens,
    db = db_name(1, temp = TRUE),
    tables = rep("flowcytometer__flowcytometer_density", length(fns_dens)),
    remove_timestamps = NULL,
    check_timestamps = FALSE,
    backup_removed = TRUE
  )
)
```
```{r addRRD_fcytraits}
## Flowcytometer Traits

fns_traits <- list.files(
  path =  file.path(params$output_dir, "flowcytometer_traits"), 
  pattern = "^flowcytometer_traits_bacteria\\..*\\.rds",
  recursive = FALSE, 
  full.names = TRUE
)

suppressMessages(
  add_to_db(
    fns_traits,
    db = db_name(1, temp = TRUE),
    tables = rep("flowcytometer__flowcytometer_traits", length(fns_traits)),
    remove_timestamps = NULL,
    check_timestamps = FALSE,
    backup_removed = TRUE
  )
)
```
```{r addRRD_indices}
RRD_create_indices(
  db_name(1, temp = TRUE), 
  LEEF = "LEEF-1", 
  continue_after_error = TRUE
)

```
```{r}
#| label: addRRD_finalize
#| 

file.rename(db_name(1, temp = TRUE), db_name(1, temp = FALSE))
```



# 2. Flowcam Stau1

The code below recalculates the densities after filtering Stau1 so that only
particles are kept with high confidence that they are indeed Stau1.

## Calculate new densities
```{r species_to_0_bemovi_25_morph_mvt_2}

options(RRDdb = db_name(1, temp = FALSE))

sql <-  paste0(
  "
    SELECT *
    FROM 'flowcam__algae_traits'
    WHERE species == 'Staurastrum1' AND species_probability > 0.95;
  "
)
  
stau1traits <- read_sql(sql = sql) %>%
  group_by(bottle)

# extrapolation.factor <- 1/0.3 # I think 0.3ml were imaged

densityStau1 <- stau1traits %>%
  group_by(
    date_flowcam,
    species,
    bottle,
    composition,
    temperature,
    incubator,
    volume_imaged,
    dilution_factor,
    richness,
    timestamp
  ) %>%
  summarize(count=n()) %>%
  mutate(density = count * (dilution_factor / volume_imaged))

# Set not found to 0

temp <- tidyr::expand_grid(
  timestamp = unique(stau1traits$timestamp),
  bottle = unique(stau1traits$bottle),
  species = "Staurastrum1"
)

densityStau1 <- full_join(densityStau1, temp) %>%
  mutate(
    count = ifelse(is.na(count),0,count),
    density = ifelse(is.na(density),0,density)
  )
```


## Update RRD
Delete from traits and add re-calculated ones.

```{r}
#| label: update_RRD
#| 
file.copy(db_name(1, temp = FALSE), db_name(2, temp = TRUE))

conn <- DBI::dbConnect(
  drv = RSQLite::SQLite(),
  db = db_name(2, temp = TRUE)
)
DBI::dbBegin(conn)


message("Deleting flowcam entries from flowcam__algae_traits ...")
delete_sql <- paste0(
  "DELETE ",
  "FROM flowcam__algae_traits ",
  "WHERE (species == \"Staurastrum1\" AND species_probability <= 0.95)"
)
message("Executing query '", delete_sql, "`...")
rd <- DBI::dbExecute(conn, delete_sql)
message("   ", rd, " rows deleted.")

message("Deleting flowcam densities from RRD ...")
delete_sql <- paste0(
  "DELETE ",
  "FROM flowcam__algae_density ",
  "WHERE (species == \"Staurastrum1\"); "
)
message("Executing query '", delete_sql, "`...")
rd <- DBI::dbExecute(conn, delete_sql)
message("   ", rd, " rows deleted.")


message("Adding flowcam densities to RRD ...")
DBI::dbWriteTable(
  conn,
  name = "flowcam__algae_density",
  value = densityStau1,
  overwrite = FALSE,
  append = TRUE
)
message("   ", nrow(densityStau1), " rows added")

## close

DBI::dbCommit(conn)
DBI::dbDisconnect(conn)

file.rename(db_name(2, temp = TRUE), db_name(2, temp = FALSE))
```



# 3. TODO Add O2, Manualcount and TOC measuremnts 

## Prepare
```{r}
#| label: prepare_tab
file.copy(db_name(2, temp = FALSE), db_name(3, temp = TRUE))
```

### Add detrended TOC - Removing the linear trend in the water chemistry 
```{r}
#| label: add_toc
#| 

toc <- readRDS(params$toc) %>%
  left_join(
    db_read_table(db = db_name(3, temp = TRUE), table = "experimental_design") %>% 
      collect(),
    by = join_by(bottle)
    ) %>%
  filter(!is.na(conc))

colnames_toc <- colnames(toc)

toc$day <- as.Date(as.character(toc$timestamp), "%Y%m%d") - min(as.Date(as.character(toc$timestamp), "%Y%m%d") )
toc$day <- as.numeric(toc$day)

toc$analysis_time2 <- lubridate::as_datetime(toc$anaysis_time, format="%Y-%m-%d %H:%M") # wrong time zones, but doesn't matter 
toc$analysis_time2 <- sapply(toc$analysis_time2, function(d){
  paste0(unlist(strsplit(as.character(d), "-")), collapse = "")
})

toc <- toc %>%
  dplyr::mutate(
    light_phase = case_when(
      temperature =="constant" ~ "constant",
      day < 93 ~ "constant before decrease",
      day >= 93 & day < 198 ~ "decreasing",
      day >= 198 ~ "constant after decrease"),
    int = interaction(analysis_time2,light_phase
    )
  )  %>%
  arrange(timestamp)

toc_list <- split(
  toc, 
  f = toc$int, 
  drop = T
)

toc_list <- pbmcapply::pbmclapply(
  toc_list, 
  function(df){
    if(nrow(df) < 3*4) { # at least 3 bottles per type to do the detrending
      df$concentration.detrended <- df$conc
      return(df)
    }
    
    df <- lapply(
      c("IC", "TC", "TN", "TOC"), 
      function(Type){
        df2 <- df %>% filter(inj_type==Type)
        m <- lm(conc ~ position, data = df2)
        predict <- predict(m) - predict(m)[1]
        df2$concentration.detrended <- df2$conc - predict
        df2
      }
    )
    do.call("rbind",df)
  }, 
  mc.cores = 7
)

toc <- do.call("rbind",toc_list)

toc <- toc |>
  select(
    -c(
      "temperature", 
      "richness", 
      "composition", 
      "incubator", 
      "day", 
      "analysis_time2", 
      "light_phase", 
      "int", 
      "concentration.detrended")
  )
toc_det <- tempfile(fileext = ".rds")
saveRDS(toc, toc_det)

add_to_db(
  toc_det,
  db = db_name(3, temp = TRUE),
  tables = "toc__toc",
  remove_timestamps = NULL,
  check_timestamps = TRUE,
  backup_removed = TRUE
)

unlink(toc_det)
```

### Add O2
```{r}
#| label: add_o2
#| 

fns_o2 <- list.files(
  path = params$extracted_dir, 
  pattern = "^LEEF\\.fast\\.o2meter\\.",
  recursive = FALSE, 
  full.names = TRUE
) |>
  file.path("o2meter.csv")

suppressMessages(
  add_to_db(
    fns_o2,
    db = db_name(3, temp = TRUE),
    tables = rep("o2meter__o2meter", length(fns_o2)),
    remove_timestamps = NULL,
    check_timestamps = TRUE,
    backup_removed = TRUE
  )
)
```


### Add manualcount
```{r}
#| label: add_manualcount
#| 

fns_mc <- list.files(
  path = params$extracted_dir, 
  pattern = "^LEEF\\.fast\\.manualcount\\.",
  recursive = FALSE, 
  full.names = TRUE
) |>
  file.path("manualcount_density.csv")

suppressMessages(
  add_to_db(
    fns_mc,
    db = db_name(3, temp = TRUE),
    tables = rep("manualcount__manualcount_density", length(fns_mc)),
    remove_timestamps = NULL,
    check_timestamps = TRUE,
    backup_removed = TRUE
  )
)
```


## Finalize
```{r}
#| label: finalize_tab
#| 
file.rename(db_name(3, temp = TRUE), db_name(3, temp = FALSE))
```

# Create Diagnostic Report
The Diagnostic report needs to be created before the renaming as it does rely on the otriginal terminology.

```{r}
#| label: createDiagReport
#| 

report_diagnostic(
  db = db_name(3, temp = FALSE),  
  template = "LEEF_1",
  suffix = paste0("reclassified_", params$version_tag), 
  format = "html"
)
```


# 4. Rename species and columns
```{r}
#| label: rename

file.copy(db_name(3, temp = FALSE), db_name(4, temp = TRUE))

RRD_LEEF_1_rename(db = db_name(4, temp = TRUE))

file.rename(db_name(4, temp = TRUE), db_name(4, temp = FALSE))
```

```{r}
#| label: create final db

file.copy(db_name(4, temp = FALSE), db_name("final", temp = FALSE))
```

# Do a final vacuuming into new database
Vacuuming the database will take some time!

To vacuum the sqlite database, i.e. recover the space from the deletion of rows, please run the following command in the directory where the database is located. I do not expect this to have a big impact on the size.

```{r echo = FALSE}
cat(
  paste0(
    "sqlite3 \"./", basename(db_name("final", temp = FALSE)), "\" 'VACUUM main INTO \"", db_name("final_vacuumed", temp = FALSE), "\"'"
    )
)
```

# Create Overlays
This is still using the extracted and pre-processed folder and needs to be changed to use the reclassified bemovi data. 
```{r}
#| label: overlays
#| eval: false

generate_overlays(
  params = params,
  overwrite = FALSE
)
```



